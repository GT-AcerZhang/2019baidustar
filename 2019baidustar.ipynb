{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 一、模型训练\n",
    "### 1.1 准备数据和模型\n",
    "#### 1.1.1 解压`coco`数据集和`baseline_model`基线模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压数据集\n",
    "# !cd /home/aistudio/data/data7122 && unzip -qo train2017.zip -d /home/aistudio/work/coco2017/\n",
    "# !cd /home/aistudio/data/data7122 && unzip -qo test2017.zip -d /home/aistudio/work/coco2017/\n",
    "# !cd /home/aistudio/data/data7122 && unzip -qo val2017.zip -d /home/aistudio/work/coco2017/\n",
    "# !cd /home/aistudio/data/data7122 && unzip -qo image_info_test2017.zip -d /home/aistudio/work/coco2017/\n",
    "# !cd /home/aistudio/data/data7122 && unzip -qo annotations_trainval2017.zip -d /home/aistudio/work/coco2017/\n",
    "# !cd /home/aistudio/data/data7122 && unzip -qo PaddlePaddle_baseline_model.zip -d /home/aistudio/work/\n",
    "# !cd work/coco2017/train2017 && ls |wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.1.2 下载ssd_mobilenet_v1_coco预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download the pretrained_model.\n",
    "# !echo \"Downloading pretrained_model ...\"\n",
    "# !cd /home/aistudio/work/pretrained_model && wget http://paddlemodels.bj.bcebos.com/ssd_mobilenet_v1_coco.tar.gz\n",
    "# !echo \"Extractint...\"\n",
    "# !cd /home/aistudio/work/pretrained_model && tar -xf ssd_mobilenet_v1_coco.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.2 下载coco数据集python api 依赖包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#安装coco数据集工具包\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.3 构建代码训练模型\n",
    "#### 1.3.1 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#导入依赖\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import functools\n",
    "import shutil\n",
    "import math\n",
    "import multiprocessing\n",
    "\n",
    "#加载参数\n",
    "def set_paddle_flags(**kwargs):\n",
    "    for key, value in kwargs.items():\n",
    "        if os.environ.get(key, None) is None:\n",
    "            os.environ[key] = str(value)\n",
    "\n",
    "\n",
    "# 这些flags需要在`import paddle`之前启用\n",
    "set_paddle_flags(\n",
    "    FLAGS_eager_delete_tensor_gb=0,  # enable GC to save memory\n",
    ")\n",
    "\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.2 设置全局变量参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#全部变量参数\n",
    "g_learning_rate = 0.001\n",
    "# g_learning_rate = 0.00007\n",
    "g_batch_size = 64\n",
    "# g_batch_size = 32\n",
    "g_epoc_num = 120\n",
    "g_use_gpu = True\n",
    "#是否并行运行\n",
    "g_parallel = True\n",
    "#数据集名称：coco2017\n",
    "g_dataset = 'coco2017'\n",
    "g_model_save_dir = '/home/aistudio/work/models/mobilenet_ssd.model'\n",
    "g_score_threshold = 0.005\n",
    "g_nms_topk = 400\n",
    "g_nms_posk = 100\n",
    "g_nms_threshold = 0.45\n",
    "#预训练模型\n",
    "# g_pretrained_model = '/home/aistudio/work/pretrained_model/ssd_mobilenet_v1_coco/'\n",
    "g_pretrained_model = '/home/aistudio/work/models/mobilenet_ssd.model/34_best/'\n",
    "# g_pretrained_model = ''\n",
    "g_ap_version = '11point'\n",
    "#输入图片的shape\n",
    "g_image_shape = '3,300,300'\n",
    "#将被减去的B,G,R通道的平均值\n",
    "g_mean_BGR = '127.5,127.5,127.5'\n",
    "#数据源文件夹\n",
    "g_data_dir = '/home/aistudio/work/coco2017/'\n",
    "#是否使用多进程\n",
    "g_use_multiprocess = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.3 设置数据集变量参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_parameters = {\n",
    "    \"coco2017\": {\n",
    "        \"train_images\": 118287,\n",
    "        \"image_shape\": [3, 300, 300],\n",
    "        # \"class_num\": 91,\n",
    "        \"class_num\": 81,\n",
    "        \"batch_size\": 64,\n",
    "        \"lr\": 0.001,\n",
    "        \"lr_epochs\": [12, 19],\n",
    "        \"lr_decay\": [1, 0.5, 0.25],\n",
    "        \"ap_version\": 'integral', # should use eval_coco_map.py to test model\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.4 图像预处理工具`image_util`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image_util\n",
    "from PIL import Image, ImageEnhance, ImageDraw\n",
    "from PIL import ImageFile\n",
    "import random\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  #otherwise IOError raised image file is truncated\n",
    "\n",
    "\n",
    "class sampler():\n",
    "    def __init__(self, max_sample, max_trial, min_scale, max_scale,\n",
    "                 min_aspect_ratio, max_aspect_ratio, min_jaccard_overlap,\n",
    "                 max_jaccard_overlap):\n",
    "        self.max_sample = max_sample\n",
    "        self.max_trial = max_trial\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.min_aspect_ratio = min_aspect_ratio\n",
    "        self.max_aspect_ratio = max_aspect_ratio\n",
    "        self.min_jaccard_overlap = min_jaccard_overlap\n",
    "        self.max_jaccard_overlap = max_jaccard_overlap\n",
    "\n",
    "\n",
    "class bbox():\n",
    "    def __init__(self, xmin, ymin, xmax, ymax):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "\n",
    "def bbox_area(src_bbox):\n",
    "    width = src_bbox.xmax - src_bbox.xmin\n",
    "    height = src_bbox.ymax - src_bbox.ymin\n",
    "    return width * height\n",
    "\n",
    "\n",
    "def generate_sample(sampler):\n",
    "    scale = np.random.uniform(sampler.min_scale, sampler.max_scale)\n",
    "    aspect_ratio = np.random.uniform(sampler.min_aspect_ratio,\n",
    "                                  sampler.max_aspect_ratio)\n",
    "    aspect_ratio = max(aspect_ratio, (scale**2.0))\n",
    "    aspect_ratio = min(aspect_ratio, 1 / (scale**2.0))\n",
    "\n",
    "    bbox_width = scale * (aspect_ratio**0.5)\n",
    "    bbox_height = scale / (aspect_ratio**0.5)\n",
    "    xmin_bound = 1 - bbox_width\n",
    "    ymin_bound = 1 - bbox_height\n",
    "    xmin = np.random.uniform(0, xmin_bound)\n",
    "    ymin = np.random.uniform(0, ymin_bound)\n",
    "    xmax = xmin + bbox_width\n",
    "    ymax = ymin + bbox_height\n",
    "    sampled_bbox = bbox(xmin, ymin, xmax, ymax)\n",
    "    return sampled_bbox\n",
    "\n",
    "\n",
    "def jaccard_overlap(sample_bbox, object_bbox):\n",
    "    if sample_bbox.xmin >= object_bbox.xmax or \\\n",
    "            sample_bbox.xmax <= object_bbox.xmin or \\\n",
    "            sample_bbox.ymin >= object_bbox.ymax or \\\n",
    "            sample_bbox.ymax <= object_bbox.ymin:\n",
    "        return 0\n",
    "    intersect_xmin = max(sample_bbox.xmin, object_bbox.xmin)\n",
    "    intersect_ymin = max(sample_bbox.ymin, object_bbox.ymin)\n",
    "    intersect_xmax = min(sample_bbox.xmax, object_bbox.xmax)\n",
    "    intersect_ymax = min(sample_bbox.ymax, object_bbox.ymax)\n",
    "    intersect_size = (intersect_xmax - intersect_xmin) * (\n",
    "        intersect_ymax - intersect_ymin)\n",
    "    sample_bbox_size = bbox_area(sample_bbox)\n",
    "    object_bbox_size = bbox_area(object_bbox)\n",
    "    overlap = intersect_size / (\n",
    "        sample_bbox_size + object_bbox_size - intersect_size)\n",
    "    return overlap\n",
    "\n",
    "\n",
    "def satisfy_sample_constraint(sampler, sample_bbox, bbox_labels):\n",
    "    if sampler.min_jaccard_overlap == 0 and sampler.max_jaccard_overlap == 0:\n",
    "        return True\n",
    "    for i in range(len(bbox_labels)):\n",
    "        object_bbox = bbox(bbox_labels[i][1], bbox_labels[i][2],\n",
    "                           bbox_labels[i][3], bbox_labels[i][4])\n",
    "        overlap = jaccard_overlap(sample_bbox, object_bbox)\n",
    "        if sampler.min_jaccard_overlap != 0 and \\\n",
    "                overlap < sampler.min_jaccard_overlap:\n",
    "            continue\n",
    "        if sampler.max_jaccard_overlap != 0 and \\\n",
    "                overlap > sampler.max_jaccard_overlap:\n",
    "            continue\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def generate_batch_samples(batch_sampler, bbox_labels):\n",
    "    sampled_bbox = []\n",
    "    index = []\n",
    "    c = 0\n",
    "    for sampler in batch_sampler:\n",
    "        found = 0\n",
    "        for i in range(sampler.max_trial):\n",
    "            if found >= sampler.max_sample:\n",
    "                break\n",
    "            sample_bbox = generate_sample(sampler)\n",
    "            if satisfy_sample_constraint(sampler, sample_bbox, bbox_labels):\n",
    "                sampled_bbox.append(sample_bbox)\n",
    "                found = found + 1\n",
    "                index.append(c)\n",
    "        c = c + 1\n",
    "    return sampled_bbox\n",
    "\n",
    "\n",
    "def clip_bbox(src_bbox):\n",
    "    src_bbox.xmin = max(min(src_bbox.xmin, 1.0), 0.0)\n",
    "    src_bbox.ymin = max(min(src_bbox.ymin, 1.0), 0.0)\n",
    "    src_bbox.xmax = max(min(src_bbox.xmax, 1.0), 0.0)\n",
    "    src_bbox.ymax = max(min(src_bbox.ymax, 1.0), 0.0)\n",
    "    return src_bbox\n",
    "\n",
    "\n",
    "def meet_emit_constraint(src_bbox, sample_bbox):\n",
    "    center_x = (src_bbox.xmax + src_bbox.xmin) / 2\n",
    "    center_y = (src_bbox.ymax + src_bbox.ymin) / 2\n",
    "    if center_x >= sample_bbox.xmin and \\\n",
    "        center_x <= sample_bbox.xmax and \\\n",
    "        center_y >= sample_bbox.ymin and \\\n",
    "        center_y <= sample_bbox.ymax:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def transform_labels(bbox_labels, sample_bbox):\n",
    "    proj_bbox = bbox(0, 0, 0, 0)\n",
    "    sample_labels = []\n",
    "    for i in range(len(bbox_labels)):\n",
    "        sample_label = []\n",
    "        object_bbox = bbox(bbox_labels[i][1], bbox_labels[i][2],\n",
    "                           bbox_labels[i][3], bbox_labels[i][4])\n",
    "        if not meet_emit_constraint(object_bbox, sample_bbox):\n",
    "            continue\n",
    "        sample_width = sample_bbox.xmax - sample_bbox.xmin\n",
    "        sample_height = sample_bbox.ymax - sample_bbox.ymin\n",
    "        proj_bbox.xmin = (object_bbox.xmin - sample_bbox.xmin) / sample_width\n",
    "        proj_bbox.ymin = (object_bbox.ymin - sample_bbox.ymin) / sample_height\n",
    "        proj_bbox.xmax = (object_bbox.xmax - sample_bbox.xmin) / sample_width\n",
    "        proj_bbox.ymax = (object_bbox.ymax - sample_bbox.ymin) / sample_height\n",
    "        proj_bbox = clip_bbox(proj_bbox)\n",
    "        if bbox_area(proj_bbox) > 0:\n",
    "            sample_label.append(bbox_labels[i][0])\n",
    "            sample_label.append(float(proj_bbox.xmin))\n",
    "            sample_label.append(float(proj_bbox.ymin))\n",
    "            sample_label.append(float(proj_bbox.xmax))\n",
    "            sample_label.append(float(proj_bbox.ymax))\n",
    "            #sample_label.append(bbox_labels[i][5])\n",
    "            sample_label = sample_label + bbox_labels[i][5:]\n",
    "            sample_labels.append(sample_label)\n",
    "    return sample_labels\n",
    "\n",
    "\n",
    "def crop_image(img, bbox_labels, sample_bbox, image_width, image_height):\n",
    "    sample_bbox = clip_bbox(sample_bbox)\n",
    "    xmin = int(sample_bbox.xmin * image_width)\n",
    "    xmax = int(sample_bbox.xmax * image_width)\n",
    "    ymin = int(sample_bbox.ymin * image_height)\n",
    "    ymax = int(sample_bbox.ymax * image_height)\n",
    "    sample_img = img[ymin:ymax, xmin:xmax]\n",
    "    sample_labels = transform_labels(bbox_labels, sample_bbox)\n",
    "    return sample_img, sample_labels\n",
    "\n",
    "\n",
    "def random_brightness(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._brightness_prob:\n",
    "        delta = np.random.uniform(-settings._brightness_delta,\n",
    "                               settings._brightness_delta) + 1\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_contrast(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._contrast_prob:\n",
    "        delta = np.random.uniform(-settings._contrast_delta,\n",
    "                               settings._contrast_delta) + 1\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_saturation(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._saturation_prob:\n",
    "        delta = np.random.uniform(-settings._saturation_delta,\n",
    "                               settings._saturation_delta) + 1\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_hue(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._hue_prob:\n",
    "        delta = np.random.uniform(-settings._hue_delta, settings._hue_delta)\n",
    "        img_hsv = np.array(img.convert('HSV'))\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "def distort_image(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    # Apply different distort order\n",
    "    if prob > 0.5:\n",
    "        img = random_brightness(img, settings)\n",
    "        img = random_contrast(img, settings)\n",
    "        img = random_saturation(img, settings)\n",
    "        img = random_hue(img, settings)\n",
    "    else:\n",
    "        img = random_brightness(img, settings)\n",
    "        img = random_saturation(img, settings)\n",
    "        img = random_hue(img, settings)\n",
    "        img = random_contrast(img, settings)\n",
    "    return img\n",
    "\n",
    "\n",
    "def expand_image(img, bbox_labels, img_width, img_height, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._expand_prob:\n",
    "        if settings._expand_max_ratio - 1 >= 0.01:\n",
    "            expand_ratio = np.random.uniform(1, settings._expand_max_ratio)\n",
    "            height = int(img_height * expand_ratio)\n",
    "            width = int(img_width * expand_ratio)\n",
    "            h_off = math.floor(np.random.uniform(0, height - img_height))\n",
    "            w_off = math.floor(np.random.uniform(0, width - img_width))\n",
    "            expand_bbox = bbox(-w_off / img_width, -h_off / img_height,\n",
    "                               (width - w_off) / img_width,\n",
    "                               (height - h_off) / img_height)\n",
    "            expand_img = np.ones((height, width, 3))\n",
    "            expand_img = np.uint8(expand_img * np.squeeze(settings._img_mean))\n",
    "            expand_img = Image.fromarray(expand_img)\n",
    "            expand_img.paste(img, (int(w_off), int(h_off)))\n",
    "            bbox_labels = transform_labels(bbox_labels, expand_bbox)\n",
    "            return expand_img, bbox_labels, width, height\n",
    "    return img, bbox_labels, img_width, img_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.5 数据读取`reader`\n",
    "通过代码：\n",
    "```python\n",
    "json_category_id_to_contiguous_id = {\n",
    "    v: i + 1\n",
    "    for i, v in enumerate(coco_api.getCatIds())\n",
    "}\n",
    "```\n",
    "在读取数据时，将类别从91变为81。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#定义reader\n",
    "import xml.etree.ElementTree\n",
    "import copy\n",
    "import six\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "\n",
    "class Settings(object):\n",
    "    def __init__(self,\n",
    "                 dataset=None,\n",
    "                 data_dir=None,\n",
    "                 label_file=None,\n",
    "                 resize_h=300,\n",
    "                 resize_w=300,\n",
    "                 mean_value=[127.5, 127.5, 127.5],\n",
    "                 apply_distort=True,\n",
    "                 apply_expand=True,\n",
    "                 ap_version='11point'):\n",
    "        self._dataset = dataset\n",
    "        self._ap_version = ap_version\n",
    "        self._data_dir = data_dir\n",
    "        if 'pascalvoc' in dataset:\n",
    "            self._label_list = []\n",
    "            label_fpath = os.path.join(data_dir, label_file)\n",
    "            for line in open(label_fpath):\n",
    "                self._label_list.append(line.strip())\n",
    "\n",
    "        self._apply_distort = apply_distort\n",
    "        self._apply_expand = apply_expand\n",
    "        self._resize_height = resize_h\n",
    "        self._resize_width = resize_w\n",
    "        self._img_mean = np.array(mean_value)[:, np.newaxis, np.newaxis].astype(\n",
    "            'float32')\n",
    "        self._expand_prob = 0.5\n",
    "        self._expand_max_ratio = 4\n",
    "        self._hue_prob = 0.5\n",
    "        self._hue_delta = 18\n",
    "        self._contrast_prob = 0.5\n",
    "        self._contrast_delta = 0.5\n",
    "        self._saturation_prob = 0.5\n",
    "        self._saturation_delta = 0.5\n",
    "        self._brightness_prob = 0.5\n",
    "        self._brightness_delta = 0.125\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset\n",
    "\n",
    "    @property\n",
    "    def ap_version(self):\n",
    "        return self._ap_version\n",
    "\n",
    "    @property\n",
    "    def apply_distort(self):\n",
    "        return self._apply_expand\n",
    "\n",
    "    @property\n",
    "    def apply_distort(self):\n",
    "        return self._apply_distort\n",
    "\n",
    "    @property\n",
    "    def data_dir(self):\n",
    "        return self._data_dir\n",
    "\n",
    "    @data_dir.setter\n",
    "    def data_dir(self, data_dir):\n",
    "        self._data_dir = data_dir\n",
    "\n",
    "    @property\n",
    "    def label_list(self):\n",
    "        return self._label_list\n",
    "\n",
    "    @property\n",
    "    def resize_h(self):\n",
    "        return self._resize_height\n",
    "\n",
    "    @property\n",
    "    def resize_w(self):\n",
    "        return self._resize_width\n",
    "\n",
    "    @property\n",
    "    def img_mean(self):\n",
    "        return self._img_mean\n",
    "\n",
    "\n",
    "def preprocess(img, bbox_labels, mode, settings):\n",
    "    img_width, img_height = img.size\n",
    "    sampled_labels = bbox_labels\n",
    "    if mode == 'train':\n",
    "        if settings._apply_distort:\n",
    "            img = distort_image(img, settings)\n",
    "        if settings._apply_expand:\n",
    "            img, bbox_labels, img_width, img_height = expand_image(\n",
    "                img, bbox_labels, img_width, img_height, settings)\n",
    "        # sampling\n",
    "        batch_sampler = []\n",
    "        # hard-code here\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 1, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.1, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.3, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.5, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.7, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.9, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.0, 1.0))\n",
    "        sampled_bbox = generate_batch_samples(batch_sampler,\n",
    "                                                         bbox_labels)\n",
    "\n",
    "        img = np.array(img)\n",
    "        if len(sampled_bbox) > 0:\n",
    "            idx = int(np.random.uniform(0, len(sampled_bbox)))\n",
    "            img, sampled_labels = crop_image(\n",
    "                img, bbox_labels, sampled_bbox[idx], img_width, img_height)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "    img = img.resize((settings.resize_w, settings.resize_h), Image.ANTIALIAS)\n",
    "    img = np.array(img)\n",
    "\n",
    "    if mode == 'train':\n",
    "        mirror = int(np.random.uniform(0, 2))\n",
    "        if mirror == 1:\n",
    "            img = img[:, ::-1, :]\n",
    "            for i in six.moves.xrange(len(sampled_labels)):\n",
    "                tmp = sampled_labels[i][1]\n",
    "                sampled_labels[i][1] = 1 - sampled_labels[i][3]\n",
    "                sampled_labels[i][3] = 1 - tmp\n",
    "    # HWC to CHW\n",
    "    if len(img.shape) == 3:\n",
    "        img = np.swapaxes(img, 1, 2)\n",
    "        img = np.swapaxes(img, 1, 0)\n",
    "    # RBG to BGR\n",
    "    img = img[[2, 1, 0], :, :]\n",
    "    img = img.astype('float32')\n",
    "    img -= settings.img_mean\n",
    "    img = img * 0.007843\n",
    "    return img, sampled_labels\n",
    "\n",
    "\n",
    "def coco(settings, coco_api, file_list, mode, batch_size, shuffle, data_dir):\n",
    "    from pycocotools.coco import COCO\n",
    "\n",
    "    def reader():\n",
    "        if mode == 'train' and shuffle:\n",
    "            np.random.shuffle(file_list)\n",
    "        batch_out = []\n",
    "        for image in file_list:\n",
    "            image_name = image['file_name']\n",
    "            image_path = os.path.join(data_dir, image_name)\n",
    "            if not os.path.exists(image_path):\n",
    "                raise ValueError(\"%s is not exist, you should specify \"\n",
    "                                 \"data path correctly.\" % image_path)\n",
    "            im = Image.open(image_path)\n",
    "            if im.mode == 'L':\n",
    "                im = im.convert('RGB')\n",
    "            im_width, im_height = im.size\n",
    "            im_id = image['id']\n",
    "\n",
    "            # layout: category_id | xmin | ymin | xmax | ymax | iscrowd\n",
    "            bbox_labels = []\n",
    "            annIds = coco_api.getAnnIds(imgIds=image['id'])\n",
    "            anns = coco_api.loadAnns(annIds)\n",
    "            \n",
    "            json_category_id_to_contiguous_id = {\n",
    "                v: i + 1\n",
    "                for i, v in enumerate(coco_api.getCatIds())\n",
    "            }\n",
    "            \n",
    "            for ann in anns:\n",
    "                bbox_sample = []\n",
    "                # start from 1, leave 0 to background\n",
    "                bbox_sample.append(float(json_category_id_to_contiguous_id[ann['category_id']]))\n",
    "                # bbox_sample.append(float(ann['category_id']))\n",
    "                bbox = ann['bbox']\n",
    "                xmin, ymin, w, h = bbox\n",
    "                xmax = xmin + w\n",
    "                ymax = ymin + h\n",
    "                bbox_sample.append(float(xmin) / im_width)\n",
    "                bbox_sample.append(float(ymin) / im_height)\n",
    "                bbox_sample.append(float(xmax) / im_width)\n",
    "                bbox_sample.append(float(ymax) / im_height)\n",
    "                bbox_sample.append(float(ann['iscrowd']))\n",
    "                bbox_labels.append(bbox_sample)\n",
    "            im, sample_labels = preprocess(im, bbox_labels, mode, settings)\n",
    "            sample_labels = np.array(sample_labels)\n",
    "            if len(sample_labels) == 0: continue\n",
    "            im = im.astype('float32')\n",
    "            boxes = sample_labels[:, 1:5]\n",
    "            lbls = sample_labels[:, 0].astype('int32')\n",
    "            iscrowd = sample_labels[:, -1].astype('int32')\n",
    "            if 'cocoMAP' in settings.ap_version:\n",
    "                batch_out.append((im, boxes, lbls, iscrowd,\n",
    "                                  [im_id, im_width, im_height]))\n",
    "            else:\n",
    "                batch_out.append((im, boxes, lbls, iscrowd))\n",
    "\n",
    "            if len(batch_out) == batch_size:\n",
    "                yield batch_out\n",
    "                batch_out = []\n",
    "\n",
    "        if mode == 'test' and len(batch_out) > 1:\n",
    "            yield batch_out\n",
    "            batch_out = []\n",
    "\n",
    "    return reader\n",
    "\n",
    "\n",
    "def pascalvoc(settings, file_list, mode, batch_size, shuffle):\n",
    "    def reader():\n",
    "        if mode == 'train' and shuffle:\n",
    "            np.random.shuffle(file_list)\n",
    "        batch_out = []\n",
    "        cnt = 0\n",
    "        for image in file_list:\n",
    "            image_path, label_path = image.split()\n",
    "            image_path = os.path.join(settings.data_dir, image_path)\n",
    "            label_path = os.path.join(settings.data_dir, label_path)\n",
    "            if not os.path.exists(image_path):\n",
    "                raise ValueError(\"%s is not exist, you should specify \"\n",
    "                                 \"data path correctly.\" % image_path)\n",
    "            im = Image.open(image_path)\n",
    "            if im.mode == 'L':\n",
    "                im = im.convert('RGB')\n",
    "            im_width, im_height = im.size\n",
    "\n",
    "            # layout: label | xmin | ymin | xmax | ymax | difficult\n",
    "            bbox_labels = []\n",
    "            root = xml.etree.ElementTree.parse(label_path).getroot()\n",
    "            for object in root.findall('object'):\n",
    "                bbox_sample = []\n",
    "                # start from 1\n",
    "                bbox_sample.append(\n",
    "                    float(settings.label_list.index(object.find('name').text)))\n",
    "                bbox = object.find('bndbox')\n",
    "                difficult = float(object.find('difficult').text)\n",
    "                bbox_sample.append(float(bbox.find('xmin').text) / im_width)\n",
    "                bbox_sample.append(float(bbox.find('ymin').text) / im_height)\n",
    "                bbox_sample.append(float(bbox.find('xmax').text) / im_width)\n",
    "                bbox_sample.append(float(bbox.find('ymax').text) / im_height)\n",
    "                bbox_sample.append(difficult)\n",
    "                bbox_labels.append(bbox_sample)\n",
    "            im, sample_labels = preprocess(im, bbox_labels, mode, settings)\n",
    "            sample_labels = np.array(sample_labels)\n",
    "            if len(sample_labels) == 0: continue\n",
    "            im = im.astype('float32')\n",
    "            boxes = sample_labels[:, 1:5]\n",
    "            lbls = sample_labels[:, 0].astype('int32')\n",
    "            difficults = sample_labels[:, -1].astype('int32')\n",
    "\n",
    "            batch_out.append((im, boxes, lbls, difficults))\n",
    "            if len(batch_out) == batch_size:\n",
    "                yield batch_out\n",
    "                cnt += len(batch_out)\n",
    "                batch_out = []\n",
    "\n",
    "        if mode == 'test' and len(batch_out) > 1:\n",
    "            yield batch_out\n",
    "            cnt += len(batch_out)\n",
    "            batch_out = []\n",
    "\n",
    "    return reader\n",
    "\n",
    "\n",
    "def reader_train(settings,\n",
    "          file_list,\n",
    "          batch_size,\n",
    "          shuffle=True,\n",
    "          use_multiprocess=True,\n",
    "          num_workers=8,\n",
    "          enable_ce=False):\n",
    "    file_path = os.path.join(settings.data_dir, file_list)\n",
    "    print(\"reader_train->file_path:{}\".format(file_path))\n",
    "    readers = []\n",
    "    if 'coco' in settings.dataset:\n",
    "        # cocoapi\n",
    "        from pycocotools.coco import COCO\n",
    "        coco_api = COCO(file_path)\n",
    "        image_ids = coco_api.getImgIds()\n",
    "        images = coco_api.loadImgs(image_ids)\n",
    "        np.random.shuffle(images)\n",
    "        if '2014' in file_list:\n",
    "            sub_dir = \"train2014\"\n",
    "        elif '2017' in file_list:\n",
    "            sub_dir = \"train2017\"\n",
    "        data_dir = os.path.join(settings.data_dir, sub_dir)\n",
    "\n",
    "        n = int(math.ceil(len(images) // num_workers)) if use_multiprocess \\\n",
    "            else len(images)\n",
    "        image_lists = [images[i:i + n] for i in range(0, len(images), n)]\n",
    "        for l in image_lists:\n",
    "            readers.append(\n",
    "                coco(settings, coco_api, l, 'train', batch_size, shuffle,\n",
    "                     data_dir))\n",
    "    else:\n",
    "        images = [line.strip() for line in open(file_path)]\n",
    "        np.random.shuffle(images)\n",
    "        n = int(math.ceil(len(images) // num_workers)) if use_multiprocess \\\n",
    "            else len(images)\n",
    "        image_lists = [images[i:i + n] for i in range(0, len(images), n)]\n",
    "        for l in image_lists:\n",
    "            readers.append(pascalvoc(settings, l, 'train', batch_size, shuffle))\n",
    "    print(\"use_multiprocess \", use_multiprocess)\n",
    "    if use_multiprocess:\n",
    "        return paddle.reader.multiprocess_reader(readers, False)\n",
    "    else:\n",
    "        return readers[0]\n",
    "\n",
    "\n",
    "def reader_test(settings, file_list, batch_size):\n",
    "    file_list = os.path.join(settings.data_dir, file_list)\n",
    "    if 'coco' in settings.dataset:\n",
    "        from pycocotools.coco import COCO\n",
    "        coco_api = COCO(file_list)\n",
    "        image_ids = coco_api.getImgIds()\n",
    "        images = coco_api.loadImgs(image_ids)\n",
    "        if '2014' in file_list:\n",
    "            sub_dir = \"val2014\"\n",
    "        elif '2017' in file_list:\n",
    "            sub_dir = \"val2017\"\n",
    "        data_dir = os.path.join(settings.data_dir, sub_dir)\n",
    "        return coco(settings, coco_api, images, 'test', batch_size, False,\n",
    "                    data_dir)\n",
    "    else:\n",
    "        image_list = [line.strip() for line in open(file_list)]\n",
    "        return pascalvoc(settings, image_list, 'test', batch_size, False)\n",
    "\n",
    "\n",
    "def reader_infer(settings, image_path):\n",
    "    def reader():\n",
    "        if not os.path.exists(image_path):\n",
    "            raise ValueError(\"%s is not exist, you should specify \"\n",
    "                             \"data path correctly.\" % image_path)\n",
    "        img = Image.open(image_path)\n",
    "        if img.mode == 'L':\n",
    "            img = img.convert('RGB')\n",
    "        im_width, im_height = img.size\n",
    "        img = img.resize((settings.resize_w, settings.resize_h),\n",
    "                         Image.ANTIALIAS)\n",
    "        img = np.array(img)\n",
    "        # HWC to CHW\n",
    "        if len(img.shape) == 3:\n",
    "            img = np.swapaxes(img, 1, 2)\n",
    "            img = np.swapaxes(img, 1, 0)\n",
    "        # RBG to BGR\n",
    "        img = img[[2, 1, 0], :, :]\n",
    "        img = img.astype('float32')\n",
    "        img -= settings.img_mean\n",
    "        img = img * 0.007843\n",
    "        return img\n",
    "\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.6 设置优化器策略`optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#设置优化策略\n",
    "def optimizer_setting(train_params):\n",
    "    train_batch_size = train_params[\"batch_size\"]\n",
    "    train_iters = train_params[\"train_images\"] // train_batch_size\n",
    "    train_lr = train_params[\"lr\"]\n",
    "    boundaries = [i * train_iters  for i in train_params[\"lr_epochs\"]]\n",
    "    values = [ i * train_lr for i in train_params[\"lr_decay\"]]\n",
    "\n",
    "    optimizer = fluid.optimizer.RMSProp(\n",
    "        learning_rate=fluid.layers.piecewise_decay(boundaries, values),\n",
    "        regularization=fluid.regularizer.L2Decay(0.00005), )\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.7 自定义网络结构`mobilev2 net ssd`（loss降不下去，效果不好）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from paddle.fluid.initializer import MSRA\n",
    "# from paddle.fluid.param_attr import ParamAttr\n",
    "\n",
    "# class MobileNetV2SSD():\n",
    "#     def __init__(self, img, num_classes, img_shape, change_depth=False):\n",
    "#         self.img = img\n",
    "#         self.num_classes = num_classes\n",
    "#         self.img_shape = img_shape\n",
    "#         self.change_depth = change_depth\n",
    "\n",
    "#     def net(self, scale=1.0):\n",
    "#         change_depth = self.change_depth\n",
    "#         # if change_depth is True, the new depth is 1.4 times as deep as before.\n",
    "#         bottleneck_params_list = [\n",
    "#             (1, 16, 1, 1),\n",
    "#             (6, 24, 2, 2),\n",
    "#             (6, 32, 3, 2),\n",
    "#             (6, 64, 4, 2),\n",
    "#             (6, 96, 3, 1),\n",
    "#             (6, 160, 3, 2),\n",
    "#             (6, 320, 1, 1),\n",
    "#         ] if change_depth == False else [\n",
    "#             (1, 16, 1, 1),\n",
    "#             (6, 24, 2, 2),\n",
    "#             (6, 32, 5, 2),\n",
    "#             (6, 64, 7, 2),\n",
    "#             (6, 96, 5, 1),\n",
    "#             (6, 160, 3, 2),\n",
    "#             (6, 320, 1, 1),\n",
    "#         ]\n",
    "\n",
    "#         # conv1\n",
    "#         input = self.conv_bn_layer(\n",
    "#             self.img,\n",
    "#             num_filters=int(32 * scale),\n",
    "#             filter_size=3,\n",
    "#             stride=2,\n",
    "#             padding=1,\n",
    "#             if_act=True,\n",
    "#             name='conv1_1')\n",
    "\n",
    "#         # bottleneck sequences\n",
    "#         i = 1\n",
    "#         in_c = int(32 * scale)\n",
    "#         module11 = None\n",
    "#         for layer_setting in bottleneck_params_list:\n",
    "#             t, c, n, s = layer_setting\n",
    "#             i += 1\n",
    "#             input = self.invresi_blocks(\n",
    "#                 input=input,\n",
    "#                 in_c=in_c,\n",
    "#                 t=t,\n",
    "#                 c=int(c * scale),\n",
    "#                 n=n,\n",
    "#                 s=s,\n",
    "#                 name='conv' + str(i))\n",
    "#             if i==6:\n",
    "#                 # 19x19\n",
    "#                 module11 = self.conv_bn_layer(input=input,num_filters=512,filter_size=1,stride=1,padding=0,if_act=True,name='ssd1')\n",
    "#             in_c = int(c * scale)\n",
    "#         # last_conv\n",
    "#         tmp = self.conv_bn_layer(\n",
    "#             input=input,\n",
    "#             num_filters=int(1280 * scale) if scale > 1.0 else 1280,\n",
    "#             filter_size=1,\n",
    "#             stride=1,\n",
    "#             padding=0,\n",
    "#             if_act=True,\n",
    "#             name='conv9')\n",
    "#         module13 = self.conv_bn_layer(input=tmp,num_filters=1024,filter_size=1,stride=1,padding=0,if_act=True,name='ssd2')\n",
    "#         # 10x10\n",
    "#         module14 = self.extra_block(module13, 256, 512, 1, 2, scale)\n",
    "#         # 5x5\n",
    "#         module15 = self.extra_block(module14, 128, 256, 1, 2, scale)\n",
    "#         # 3x3\n",
    "#         module16 = self.extra_block(module15, 128, 256, 1, 2, scale)\n",
    "#         # 2x2\n",
    "#         module17 = self.extra_block(module16, 64, 128, 1, 2, scale)\n",
    "\n",
    "#         # mbox_locs：预测的输入框的位置\n",
    "#         # mbox_confs：预测框对输入的置信度\n",
    "#         # box：PriorBox输出的先验框\n",
    "#         # box_var：PriorBox的扩展方差\n",
    "#         mbox_locs, mbox_confs, box, box_var = fluid.layers.multi_box_head(\n",
    "#             inputs=[\n",
    "#                 module11, module13, module14, module15, module16, module17\n",
    "#             ],\n",
    "#             image=self.img,\n",
    "#             num_classes=self.num_classes,\n",
    "#             min_ratio=20,\n",
    "#             max_ratio=90,\n",
    "#             min_sizes=[60.0, 105.0, 150.0, 195.0, 240.0, 285.0],\n",
    "#             max_sizes=[[], 150.0, 195.0, 240.0, 285.0, 300.0],\n",
    "#             aspect_ratios=[[2.], [2., 3.], [2., 3.], [2., 3.], [2., 3.],\n",
    "#                           [2., 3.]],\n",
    "#             base_size=self.img_shape[2],\n",
    "#             offset=0.5,\n",
    "#             flip=True)\n",
    "\n",
    "#         return mbox_locs, mbox_confs, box, box_var\n",
    "\n",
    "#     def conv_bn_layer(self,\n",
    "#                       input,\n",
    "#                       filter_size,\n",
    "#                       num_filters,\n",
    "#                       stride,\n",
    "#                       padding,\n",
    "#                       channels=None,\n",
    "#                       num_groups=1,\n",
    "#                       if_act=True,\n",
    "#                       name=None,\n",
    "#                       use_cudnn=True):\n",
    "#         conv = fluid.layers.conv2d(\n",
    "#             input=input,\n",
    "#             num_filters=num_filters,\n",
    "#             filter_size=filter_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#             groups=num_groups,\n",
    "#             act=None,\n",
    "#             use_cudnn=use_cudnn,\n",
    "#             param_attr=ParamAttr(name=name + '_weights'),\n",
    "#             bias_attr=False)\n",
    "#         bn_name = name + '_bn'\n",
    "#         bn = fluid.layers.batch_norm(\n",
    "#             input=conv,\n",
    "#             param_attr=ParamAttr(name=bn_name + \"_scale\"),\n",
    "#             bias_attr=ParamAttr(name=bn_name + \"_offset\"),\n",
    "#             moving_mean_name=bn_name + '_mean',\n",
    "#             moving_variance_name=bn_name + '_variance')\n",
    "#         if if_act:\n",
    "#             return fluid.layers.relu6(bn)\n",
    "#         else:\n",
    "#             return bn\n",
    "\n",
    "#     def shortcut(self, input, data_residual):\n",
    "#         return fluid.layers.elementwise_add(input, data_residual)\n",
    "\n",
    "#     def inverted_residual_unit(self,\n",
    "#                               input,\n",
    "#                               num_in_filter,\n",
    "#                               num_filters,\n",
    "#                               ifshortcut,\n",
    "#                               stride,\n",
    "#                               filter_size,\n",
    "#                               padding,\n",
    "#                               expansion_factor,\n",
    "#                               name=None):\n",
    "#         num_expfilter = int(round(num_in_filter * expansion_factor))\n",
    "\n",
    "#         channel_expand = self.conv_bn_layer(\n",
    "#             input=input,\n",
    "#             num_filters=num_expfilter,\n",
    "#             filter_size=1,\n",
    "#             stride=1,\n",
    "#             padding=0,\n",
    "#             num_groups=1,\n",
    "#             if_act=True,\n",
    "#             name=name + '_expand')\n",
    "\n",
    "#         bottleneck_conv = self.conv_bn_layer(\n",
    "#             input=channel_expand,\n",
    "#             num_filters=num_expfilter,\n",
    "#             filter_size=filter_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#             num_groups=num_expfilter,\n",
    "#             if_act=True,\n",
    "#             name=name + '_dwise',\n",
    "#             use_cudnn=False)\n",
    "\n",
    "#         linear_out = self.conv_bn_layer(\n",
    "#             input=bottleneck_conv,\n",
    "#             num_filters=num_filters,\n",
    "#             filter_size=1,\n",
    "#             stride=1,\n",
    "#             padding=0,\n",
    "#             num_groups=1,\n",
    "#             if_act=False,\n",
    "#             name=name + '_linear')\n",
    "#         if ifshortcut:\n",
    "#             out = self.shortcut(input=input, data_residual=linear_out)\n",
    "#             return out\n",
    "#         else:\n",
    "#             return linear_out\n",
    "\n",
    "#     def invresi_blocks(self, input, in_c, t, c, n, s, name=None):\n",
    "#         first_block = self.inverted_residual_unit(\n",
    "#             input=input,\n",
    "#             num_in_filter=in_c,\n",
    "#             num_filters=c,\n",
    "#             ifshortcut=False,\n",
    "#             stride=s,\n",
    "#             filter_size=3,\n",
    "#             padding=1,\n",
    "#             expansion_factor=t,\n",
    "#             name=name + '_1')\n",
    "\n",
    "#         last_residual_block = first_block\n",
    "#         last_c = c\n",
    "\n",
    "#         for i in range(1, n):\n",
    "#             last_residual_block = self.inverted_residual_unit(\n",
    "#                 input=last_residual_block,\n",
    "#                 num_in_filter=last_c,\n",
    "#                 num_filters=c,\n",
    "#                 ifshortcut=True,\n",
    "#                 stride=1,\n",
    "#                 filter_size=3,\n",
    "#                 padding=1,\n",
    "#                 expansion_factor=t,\n",
    "#                 name=name + '_' + str(i + 1))\n",
    "#         return last_residual_block\n",
    "\n",
    "#     def extra_block(self, input, num_filters1, num_filters2, num_groups, stride,\n",
    "#                     scale):\n",
    "#         # 1x1 conv\n",
    "#         pointwise_conv = self.conv_bn(\n",
    "#             input=input,\n",
    "#             filter_size=1,\n",
    "#             num_filters=int(num_filters1 * scale),\n",
    "#             stride=1,\n",
    "#             num_groups=int(num_groups * scale),\n",
    "#             padding=0)\n",
    "\n",
    "#         # 3x3 conv\n",
    "#         normal_conv = self.conv_bn(\n",
    "#             input=pointwise_conv,\n",
    "#             filter_size=3,\n",
    "#             num_filters=int(num_filters2 * scale),\n",
    "#             stride=2,\n",
    "#             num_groups=int(num_groups * scale),\n",
    "#             padding=1)\n",
    "#         return normal_conv\n",
    "\n",
    "#     def conv_bn(self,\n",
    "#                 input,\n",
    "#                 filter_size,\n",
    "#                 num_filters,\n",
    "#                 stride,\n",
    "#                 padding,\n",
    "#                 channels=None,\n",
    "#                 num_groups=1,\n",
    "#                 act='relu',\n",
    "#                 use_cudnn=True):\n",
    "#         parameter_attr = ParamAttr(learning_rate=0.1, initializer=MSRA())\n",
    "#         conv = fluid.layers.conv2d(\n",
    "#             input=input,\n",
    "#             num_filters=num_filters,\n",
    "#             filter_size=filter_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#             groups=num_groups,\n",
    "#             act=None,\n",
    "#             use_cudnn=use_cudnn,\n",
    "#             param_attr=parameter_attr,\n",
    "#             bias_attr=False)\n",
    "#         return fluid.layers.batch_norm(input=conv, act=act)\n",
    "\n",
    "# def MobileNetV2_x0_25(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=0.25)\n",
    "\n",
    "\n",
    "# def MobileNetV2_x0_5(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=0.5)\n",
    "\n",
    "\n",
    "# def MobileNetV2_x1_0(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=1.0)\n",
    "\n",
    "\n",
    "# def MobileNetV2_x1_5(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=1.5)\n",
    "\n",
    "\n",
    "# def MobileNetV2_x2_0(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=2.0)\n",
    "\n",
    "\n",
    "# def MobileNetV2_scale(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape, change_depth=True)\n",
    "#     return model.net(scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.8 定义网络结构`mobile net ssd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.initializer import MSRA\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "\n",
    "\n",
    "class MobileNetSSD:\n",
    "    def __init__(self, img, num_classes, img_shape):\n",
    "        self.img = img\n",
    "        self.num_classes = num_classes\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "    def ssd_net(self, scale=1.0):\n",
    "        # 300x300\n",
    "        tmp = self.conv_bn(self.img, 3, int(32 * scale), 2, 1, 3)\n",
    "        # 150x150\n",
    "        tmp = self.depthwise_separable(tmp, 32, 64, 32, 1, scale)\n",
    "        tmp = self.depthwise_separable(tmp, 64, 128, 64, 2, scale)\n",
    "        # 75x75\n",
    "        tmp = self.depthwise_separable(tmp, 128, 128, 128, 1, scale)\n",
    "        tmp = self.depthwise_separable(tmp, 128, 256, 128, 2, scale)\n",
    "        # 38x38\n",
    "        tmp = self.depthwise_separable(tmp, 256, 256, 256, 1, scale)\n",
    "        tmp = self.depthwise_separable(tmp, 256, 512, 256, 2, scale)\n",
    "\n",
    "        # 19x19\n",
    "        for i in range(5):\n",
    "            tmp = self.depthwise_separable(tmp, 512, 512, 512, 1, scale)\n",
    "        module11 = tmp\n",
    "        tmp = self.depthwise_separable(tmp, 512, 1024, 512, 2, scale)\n",
    "\n",
    "        # 10x10\n",
    "        module13 = self.depthwise_separable(tmp, 1024, 1024, 1024, 1, scale)\n",
    "        module14 = self.extra_block(module13, 256, 512, 1, 2, scale)\n",
    "        # 5x5\n",
    "        module15 = self.extra_block(module14, 128, 256, 1, 2, scale)\n",
    "        # 3x3\n",
    "        module16 = self.extra_block(module15, 128, 256, 1, 2, scale)\n",
    "        # 2x2\n",
    "        module17 = self.extra_block(module16, 64, 128, 1, 2, scale)\n",
    "\n",
    "        mbox_locs, mbox_confs, box, box_var = fluid.layers.multi_box_head(\n",
    "            inputs=[\n",
    "                module11, module13, module14, module15, module16, module17\n",
    "            ],\n",
    "            image=self.img,\n",
    "            num_classes=self.num_classes,\n",
    "            min_ratio=20,\n",
    "            max_ratio=90,\n",
    "            min_sizes=[60.0, 105.0, 150.0, 195.0, 240.0, 285.0],\n",
    "            max_sizes=[[], 150.0, 195.0, 240.0, 285.0, 300.0],\n",
    "            aspect_ratios=[[2.], [2., 3.], [2., 3.], [2., 3.], [2., 3.],\n",
    "                          [2., 3.]],\n",
    "            base_size=self.img_shape[2],\n",
    "            offset=0.5,\n",
    "            flip=True)\n",
    "\n",
    "        return mbox_locs, mbox_confs, box, box_var\n",
    "\n",
    "    def conv_bn(self,\n",
    "                input,\n",
    "                filter_size,\n",
    "                num_filters,\n",
    "                stride,\n",
    "                padding,\n",
    "                channels=None,\n",
    "                num_groups=1,\n",
    "                act='relu',\n",
    "                use_cudnn=True):\n",
    "        parameter_attr = ParamAttr(learning_rate=0.1, initializer=MSRA())\n",
    "        conv = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            groups=num_groups,\n",
    "            act=None,\n",
    "            use_cudnn=use_cudnn,\n",
    "            param_attr=parameter_attr,\n",
    "            bias_attr=False)\n",
    "        return fluid.layers.batch_norm(input=conv, act=act)\n",
    "\n",
    "    def depthwise_separable(self, input, num_filters1, num_filters2, num_groups,\n",
    "                            stride, scale):\n",
    "        depthwise_conv = self.conv_bn(\n",
    "            input=input,\n",
    "            filter_size=3,\n",
    "            num_filters=int(num_filters1 * scale),\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            num_groups=int(num_groups * scale),\n",
    "            use_cudnn=False)\n",
    "\n",
    "        pointwise_conv = self.conv_bn(\n",
    "            input=depthwise_conv,\n",
    "            filter_size=1,\n",
    "            num_filters=int(num_filters2 * scale),\n",
    "            stride=1,\n",
    "            padding=0)\n",
    "        return pointwise_conv\n",
    "\n",
    "    def extra_block(self, input, num_filters1, num_filters2, num_groups, stride,\n",
    "                    scale):\n",
    "        # 1x1 conv\n",
    "        pointwise_conv = self.conv_bn(\n",
    "            input=input,\n",
    "            filter_size=1,\n",
    "            num_filters=int(num_filters1 * scale),\n",
    "            stride=1,\n",
    "            num_groups=int(num_groups * scale),\n",
    "            padding=0)\n",
    "\n",
    "        # 3x3 conv\n",
    "        normal_conv = self.conv_bn(\n",
    "            input=pointwise_conv,\n",
    "            filter_size=3,\n",
    "            num_filters=int(num_filters2 * scale),\n",
    "            stride=2,\n",
    "            num_groups=int(num_groups * scale),\n",
    "            padding=1)\n",
    "        return normal_conv\n",
    "\n",
    "\n",
    "def build_mobilenet_ssd(img, num_classes, img_shape):\n",
    "    ssd_model = MobileNetSSD(img, num_classes, img_shape)\n",
    "    return ssd_model.ssd_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.9 修改ssd_loss函数，替换原有框架中ssd_loss函数\n",
    "主要拆分其中nn.softmax_with_cross_entropy函数为nn.softmax和nn.cross_entropy两个函数，避免后续量化、剪枝操作后的训练中，loss为NAN的错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.layers import nn, iou_similarity, bipartite_match, target_assign, tensor, box_coder\n",
    "\n",
    "\n",
    "def ssd_loss(location,\n",
    "             confidence,\n",
    "             gt_box,\n",
    "             gt_label,\n",
    "             prior_box,\n",
    "             prior_box_var=None,\n",
    "             background_label=0,\n",
    "             overlap_threshold=0.5,\n",
    "             neg_pos_ratio=3.0,\n",
    "             neg_overlap=0.5,\n",
    "             loc_loss_weight=1.0,\n",
    "             conf_loss_weight=1.0,\n",
    "             match_type='per_prediction',\n",
    "             mining_type='max_negative',\n",
    "             normalize=True,\n",
    "             sample_size=None):\n",
    "\n",
    "    helper = LayerHelper('ssd_loss', **locals())\n",
    "    if mining_type != 'max_negative':\n",
    "        raise ValueError(\"Only support mining_type == max_negative now.\")\n",
    "\n",
    "    num, num_prior, num_class = confidence.shape\n",
    "    conf_shape = nn.shape(confidence)\n",
    "\n",
    "    def __reshape_to_2d(var):\n",
    "        return nn.flatten(x=var, axis=2)\n",
    "\n",
    "    # 1. Find matched boundding box by prior box.\n",
    "    #   1.1 Compute IOU similarity between ground-truth boxes and prior boxes.\n",
    "    iou = iou_similarity(x=gt_box, y=prior_box)\n",
    "    #   1.2 Compute matched boundding box by bipartite matching algorithm.\n",
    "    matched_indices, matched_dist = bipartite_match(iou, match_type,\n",
    "                                                    overlap_threshold)\n",
    "\n",
    "    # 2. Compute confidence for mining hard examples\n",
    "    # 2.1. Get the target label based on matched indices\n",
    "    gt_label = nn.reshape(\n",
    "        x=gt_label, shape=(len(gt_label.shape) - 1) * (0, ) + (-1, 1))\n",
    "    gt_label.stop_gradient = True\n",
    "    target_label, _ = target_assign(\n",
    "        gt_label, matched_indices, mismatch_value=background_label)\n",
    "    # 2.2. Compute confidence loss.\n",
    "    # Reshape confidence to 2D tensor.\n",
    "    confidence = __reshape_to_2d(confidence)\n",
    "    target_label = tensor.cast(x=target_label, dtype='int64')\n",
    "    target_label = __reshape_to_2d(target_label)\n",
    "    target_label.stop_gradient = True\n",
    "    #conf_loss = nn.softmax_with_cross_entropy(confidence, target_label)\n",
    "    conf_softmax = nn.softmax(confidence,use_cudnn=False)\n",
    "    conf_loss = nn.cross_entropy(conf_softmax, target_label)\n",
    "    # 3. Mining hard examples\n",
    "    actual_shape = nn.slice(conf_shape, axes=[0], starts=[0], ends=[2])\n",
    "    actual_shape.stop_gradient = True\n",
    "    conf_loss = nn.reshape(\n",
    "        x=conf_loss, shape=(num, num_prior), actual_shape=actual_shape)\n",
    "    conf_loss.stop_gradient = True\n",
    "    neg_indices = helper.create_variable_for_type_inference(dtype='int32')\n",
    "    dtype = matched_indices.dtype\n",
    "    updated_matched_indices = helper.create_variable_for_type_inference(\n",
    "        dtype=dtype)\n",
    "    helper.append_op(\n",
    "        type='mine_hard_examples',\n",
    "        inputs={\n",
    "            'ClsLoss': conf_loss,\n",
    "            'LocLoss': None,\n",
    "            'MatchIndices': matched_indices,\n",
    "            'MatchDist': matched_dist,\n",
    "        },\n",
    "        outputs={\n",
    "            'NegIndices': neg_indices,\n",
    "            'UpdatedMatchIndices': updated_matched_indices\n",
    "        },\n",
    "        attrs={\n",
    "            'neg_pos_ratio': neg_pos_ratio,\n",
    "            'neg_dist_threshold': neg_overlap,\n",
    "            'mining_type': mining_type,\n",
    "            'sample_size': sample_size,\n",
    "        })\n",
    "\n",
    "    # 4. Assign classification and regression targets\n",
    "    # 4.1. Encoded bbox according to the prior boxes.\n",
    "    encoded_bbox = box_coder(\n",
    "        prior_box=prior_box,\n",
    "        prior_box_var=prior_box_var,\n",
    "        target_box=gt_box,\n",
    "        code_type='encode_center_size')\n",
    "    # 4.2. Assign regression targets\n",
    "    target_bbox, target_loc_weight = target_assign(\n",
    "        encoded_bbox, updated_matched_indices, mismatch_value=background_label)\n",
    "    # 4.3. Assign classification targets\n",
    "    target_label, target_conf_weight = target_assign(\n",
    "        gt_label,\n",
    "        updated_matched_indices,\n",
    "        negative_indices=neg_indices,\n",
    "        mismatch_value=background_label)\n",
    "\n",
    "    # 5. Compute loss.\n",
    "    # 5.1 Compute confidence loss.\n",
    "    target_label = __reshape_to_2d(target_label)\n",
    "    target_label = tensor.cast(x=target_label, dtype='int64')\n",
    "\n",
    "    # conf_loss = nn.softmax_with_cross_entropy(confidence, target_label)\n",
    "    conf_softmax = nn.softmax(confidence, use_cudnn=False)\n",
    "    conf_loss = nn.cross_entropy(conf_softmax, target_label)\n",
    "    target_conf_weight = __reshape_to_2d(target_conf_weight)\n",
    "    conf_loss = conf_loss * target_conf_weight\n",
    "\n",
    "    # the target_label and target_conf_weight do not have gradient.\n",
    "    target_label.stop_gradient = True\n",
    "    target_conf_weight.stop_gradient = True\n",
    "\n",
    "    # 5.2 Compute regression loss.\n",
    "    location = __reshape_to_2d(location)\n",
    "    target_bbox = __reshape_to_2d(target_bbox)\n",
    "\n",
    "    loc_loss = nn.smooth_l1(location, target_bbox)\n",
    "    target_loc_weight = __reshape_to_2d(target_loc_weight)\n",
    "    loc_loss = loc_loss * target_loc_weight\n",
    "\n",
    "    # the target_bbox and target_loc_weight do not have gradient.\n",
    "    target_bbox.stop_gradient = True\n",
    "    target_loc_weight.stop_gradient = True\n",
    "\n",
    "    # 5.3 Compute overall weighted loss.\n",
    "    loss = conf_loss_weight * conf_loss + loc_loss_weight * loc_loss\n",
    "    # reshape to [N, Np], N is the batch size and Np is the prior box number.\n",
    "    loss = nn.reshape(x=loss, shape=(num, num_prior), actual_shape=actual_shape)\n",
    "    loss = nn.reduce_sum(loss, dim=1, keep_dim=True)\n",
    "    if normalize:\n",
    "        normalizer = nn.reduce_sum(target_loc_weight)\n",
    "        loss = loss / normalizer\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.10 构建训练用到的`program`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#建立训练(预测)主程序,从mobilenet_ssd中读取预训练模型参数\n",
    "def build_program(main_prog, startup_prog, train_params, is_train):\n",
    "    train_image_shape = train_params['image_shape']\n",
    "    train_class_num = train_params['class_num']\n",
    "    train_ap_version = train_params['ap_version']\n",
    "    outs = []\n",
    "    with fluid.program_guard(main_prog, startup_prog):\n",
    "        py_reader = fluid.layers.py_reader(\n",
    "            capacity=64,\n",
    "            shapes=[[-1] + train_image_shape, [-1, 4], [-1, 1], [-1, 1]],\n",
    "            lod_levels=[0, 1, 1, 1],\n",
    "            dtypes=[\"float32\", \"float32\", \"int32\", \"int32\"],\n",
    "            use_double_buffer=True)\n",
    "        with fluid.unique_name.guard():\n",
    "            image, gt_box, gt_label, difficult = fluid.layers.read_file(py_reader)\n",
    "            locs, confs, box, box_var = build_mobilenet_ssd(image, train_class_num, train_image_shape)\n",
    "            # locs, confs, box, box_var = MobileNetV2_x1_0(image, train_class_num, train_image_shape)\n",
    "            if is_train:\n",
    "                with fluid.unique_name.guard(\"train\"):\n",
    "                    loss = ssd_loss(locs, confs, gt_box, gt_label, box,\n",
    "                        box_var)\n",
    "                    loss = fluid.layers.reduce_sum(loss)\n",
    "                    optimizer = optimizer_setting(train_params)\n",
    "                    optimizer.minimize(loss)\n",
    "                outs = [py_reader, loss]\n",
    "            else:\n",
    "                with fluid.unique_name.guard(\"inference\"):\n",
    "                    nmsed_out = fluid.layers.detection_output(\n",
    "                        locs, confs, box, box_var, nms_threshold=0.45)\n",
    "                    map_eval = fluid.metrics.DetectionMAP(\n",
    "                        nmsed_out,\n",
    "                        gt_label,\n",
    "                        gt_box,\n",
    "                        difficult,\n",
    "                        train_class_num,\n",
    "                        overlap_threshold=0.5,\n",
    "                        evaluate_difficult=False,\n",
    "                        ap_version=train_ap_version)\n",
    "                # nmsed_out and image is used to save mode for inference\n",
    "                outs = [py_reader, map_eval, nmsed_out, image]\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.11 构建训练逻辑代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#构建训练逻辑代码\n",
    "def start_train(data_args,\n",
    "          train_params,\n",
    "          train_file_list,\n",
    "          val_file_list):\n",
    "\n",
    "    train_model_save_dir = g_model_save_dir\n",
    "    train_pretrained_model = g_pretrained_model\n",
    "    train_use_gpu = g_use_gpu\n",
    "    train_parallel = g_parallel\n",
    "\n",
    "    is_shuffle = True\n",
    "\n",
    "    if not train_use_gpu:\n",
    "        devices_num = int(os.environ.get('CPU_NUM',\n",
    "                          multiprocessing.cpu_count()))\n",
    "    else:\n",
    "        devices_num = fluid.core.get_cuda_device_count()\n",
    "\n",
    "    batch_size = train_params['batch_size']\n",
    "    epoc_num = train_params['epoc_num']\n",
    "    batch_size_per_device = batch_size // devices_num\n",
    "    num_workers = 8\n",
    "\n",
    "    startup_prog = fluid.Program()\n",
    "    train_prog = fluid.Program()\n",
    "    test_prog = fluid.Program()\n",
    "\n",
    "    #建立训练、测试数据提供器，获取loss\n",
    "    train_py_reader, loss = build_program(\n",
    "        main_prog=train_prog,\n",
    "        startup_prog=startup_prog,\n",
    "        train_params=train_params,\n",
    "        is_train=True)\n",
    "    test_py_reader, map_eval, _, _ = build_program(\n",
    "        main_prog=test_prog,\n",
    "        startup_prog=startup_prog,\n",
    "        train_params=train_params,\n",
    "        is_train=False)\n",
    "    test_prog = test_prog.clone(for_test=True)\n",
    "    \n",
    "    place = fluid.CUDAPlace(0) if train_use_gpu else fluid.CPUPlace()\n",
    "    exe = fluid.Executor(place)\n",
    "    \n",
    "    exe.run(startup_prog)\n",
    "\n",
    "    if train_pretrained_model:\n",
    "        def if_exist(var):\n",
    "            return os.path.exists(os.path.join(train_pretrained_model, var.name))\n",
    "        fluid.io.load_vars(exe, train_pretrained_model, main_program=train_prog,\n",
    "                           predicate=if_exist)\n",
    "\n",
    "    if train_parallel:\n",
    "        loss.persistable = True\n",
    "        build_strategy = fluid.BuildStrategy()\n",
    "        build_strategy.enable_inplace = True\n",
    "        build_strategy.memory_optimize = True\n",
    "        train_exe = fluid.ParallelExecutor(main_program=train_prog,\n",
    "            use_cuda=train_use_gpu, loss_name=loss.name, build_strategy=build_strategy)\n",
    "    \n",
    "    \n",
    "    test_reader = reader_test(data_args, val_file_list, batch_size)\n",
    "    test_py_reader.decorate_paddle_reader(test_reader)\n",
    "\n",
    "\n",
    "    def save_model(postfix, main_prog):\n",
    "        model_path = os.path.join(train_model_save_dir, postfix)\n",
    "        if os.path.isdir(model_path):\n",
    "            shutil.rmtree(model_path)\n",
    "        print('save models to %s' % (model_path))\n",
    "        fluid.io.save_persistables(exe, model_path, main_program=main_prog)\n",
    "\n",
    "    best_map = 0.\n",
    "    test_map = None\n",
    "    def test(epoc_id, best_map):\n",
    "        _, accum_map = map_eval.get_map_var()\n",
    "        map_eval.reset(exe)\n",
    "        every_epoc_map=[] # for CE\n",
    "        test_py_reader.start()\n",
    "        try:\n",
    "            batch_id = 0\n",
    "            while True:\n",
    "                test_map, = exe.run(test_prog, fetch_list=[accum_map])\n",
    "                if batch_id % 10 == 0:\n",
    "                    every_epoc_map.append(test_map)\n",
    "                    print(\"Batch {0}, map {1}\".format(batch_id, test_map))\n",
    "                batch_id += 1\n",
    "        except fluid.core.EOFException:\n",
    "            test_py_reader.reset()\n",
    "            \n",
    "        mean_map = np.mean(every_epoc_map)\n",
    "        print(\"Epoc {0}, test map {1}\".format(epoc_id, test_map[0]))\n",
    "        if test_map[0] > best_map:\n",
    "            best_map = test_map[0]\n",
    "            save_model('best_model', test_prog)\n",
    "        return best_map, mean_map\n",
    "\n",
    "\n",
    "    total_time = 0.0\n",
    "    for epoc_id in range(epoc_num):\n",
    "        train_reader = reader_train(data_args,\n",
    "                                train_file_list,\n",
    "                                batch_size_per_device,\n",
    "                                shuffle=is_shuffle,\n",
    "                                use_multiprocess=g_use_multiprocess,\n",
    "                                num_workers=num_workers,\n",
    "                                enable_ce=False)\n",
    "        train_py_reader.decorate_paddle_reader(train_reader)\n",
    "        epoch_idx = epoc_id + 1\n",
    "        start_time = time.time()\n",
    "        prev_start_time = start_time\n",
    "        every_epoc_loss = []\n",
    "        batch_id = 0\n",
    "        train_py_reader.start()\n",
    "        while True:\n",
    "            try:\n",
    "                prev_start_time = start_time\n",
    "                start_time = time.time()\n",
    "                if train_parallel:\n",
    "                    loss_v, = train_exe.run(fetch_list=[loss.name],return_numpy=False)\n",
    "                else:\n",
    "                    loss_v, = exe.run(train_prog, fetch_list=[loss],return_numpy=False)\n",
    "                loss_v = np.mean(np.array(loss_v))\n",
    "                every_epoc_loss.append(loss_v)\n",
    "                if batch_id % 10 == 0:\n",
    "                    print(\"Epoc {:d}, batch {:d}, loss {:.6f}, time {:.5f}\".format(\n",
    "                        epoc_id, batch_id, loss_v, start_time - prev_start_time))\n",
    "                batch_id += 1\n",
    "            except (fluid.core.EOFException, StopIteration):\n",
    "                train_reader().close()\n",
    "                train_py_reader.reset()\n",
    "                break\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_time += end_time - start_time\n",
    "        if epoc_id % 10 == 0 or epoc_id == epoc_num - 1:\n",
    "            best_map, mean_map = test(epoc_id, best_map)\n",
    "            print(\"Best test map {0}\".format(best_map))\n",
    "            # save model\n",
    "            save_model(str(epoc_id), train_prog)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1.3.12 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#主程序函数\n",
    "train_data_dir = g_data_dir\n",
    "train_dataset = g_dataset\n",
    "assert train_dataset in ['pascalvoc', 'coco2014', 'coco2017']\n",
    "\n",
    "if train_dataset == 'coco2017':\n",
    "    train_file_list = '/home/aistudio/work/coco2017/annotations/instances_train2017.json'\n",
    "    val_file_list = '/home/aistudio/work/coco2017/annotations/instances_val2017.json'\n",
    "# if train_dataset == 'coco2017':\n",
    "#     train_file_list = 'annotations/instances_train2017.json'\n",
    "#     val_file_list = 'annotations/instances_val2017.json'\n",
    "\n",
    "mean_BGR_value = [float(m) for m in g_mean_BGR.split(\",\")]\n",
    "image_shape_value = [int(m) for m in g_image_shape.split(\",\")]\n",
    "train_parameters[train_dataset]['image_shape'] = image_shape_value\n",
    "train_parameters[train_dataset]['batch_size'] = g_batch_size\n",
    "train_parameters[train_dataset]['lr'] = g_learning_rate\n",
    "train_parameters[train_dataset]['epoc_num'] = g_epoc_num\n",
    "train_parameters[train_dataset]['ap_version'] = g_ap_version\n",
    "\n",
    "data_args = Settings(\n",
    "    dataset=g_dataset,\n",
    "    data_dir=train_data_dir,\n",
    "    label_file=None,\n",
    "    resize_h=image_shape_value[1],\n",
    "    resize_w=image_shape_value[2],\n",
    "    mean_value=mean_BGR_value,\n",
    "    apply_distort=True,\n",
    "    apply_expand=True,\n",
    "    ap_version = g_ap_version)\n",
    "start_train(data_args,\n",
    "      train_parameters[train_dataset],\n",
    "      train_file_list=train_file_list,\n",
    "      val_file_list=val_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.4 保存预测模型\n",
    "保存infer模型时，构建fetch_list格式，保证模型的输出符合大赛要求。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#保存模型\n",
    "#1.3步骤训练的最佳模型路径\n",
    "# g_infer_best_dir = '/home/aistudio/work/models/mobilenet_ssd.model/best_model/'\n",
    "g_infer_best_dir = '/home/aistudio/work/models/mobilenet_ssd.model/34_best/'\n",
    "#infer模型保存地址\n",
    "g_infer_model_save_dir = '/home/aistudio/work/models/infer_models/best_models'\n",
    "\n",
    "def save_model():\n",
    "    image_shape = [3, 300, 300]\n",
    "    num_classes = 81\n",
    "    image = fluid.layers.data(name='image', shape=image_shape, dtype='float32')\n",
    "    locs, confs, box, box_var = build_mobilenet_ssd(image, num_classes,\n",
    "                                                    image_shape)\n",
    "    # locs, confs, box, box_var = MobileNetV2_x1_0(image, num_classes,\n",
    "                                                    # image_shape)\n",
    "    boxes = fluid.layers.box_coder(\n",
    "        prior_box=box,\n",
    "        prior_box_var=box_var,\n",
    "        target_box=locs,\n",
    "        code_type='decode_center_size')\n",
    "    scores = fluid.layers.nn.softmax(input=confs)\n",
    "    scores = fluid.layers.nn.transpose(scores, perm=[0, 2, 1])\n",
    "    scores.stop_gradient = True\n",
    "    \n",
    "    fetch_list = [boxes] + [scores]\n",
    "\n",
    "    place = fluid.CUDAPlace(0) if g_use_gpu else fluid.CPUPlace()\n",
    "    exe = fluid.Executor(place)\n",
    "    # yapf: disable\n",
    "    if g_infer_best_dir:\n",
    "        def if_exist(var):\n",
    "            return os.path.exists(os.path.join(g_infer_best_dir, var.name))\n",
    "        fluid.io.load_vars(exe, g_infer_best_dir, predicate=if_exist)\n",
    "    # yapf: enable\n",
    "\n",
    "    # save infer model\n",
    "    def save_infer_model(image):\n",
    "        fluid.io.save_inference_model(g_infer_model_save_dir + \"_submit_20190914_best\", [image.name], fetch_list,exe)\n",
    "\n",
    "    save_infer_model(image)\n",
    "\n",
    "save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.5 计算模型分数\n",
    "构建测试模型分数脚本，执行脚本，测试分数指标\n",
    "\n",
    "脚本`testssd.sh`内容：\n",
    "```bash\n",
    "#!/bin/bash\n",
    "python /home/aistudio/work/astar2019/score.py --model_dir /home/aistudio/work/models/pruned_models/20190915_best_1 --data_dir work/coco2017\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#计算分数\n",
    "# !cd /home/aistudio/work && tar -xzvf astar2019.tar.gz\n",
    "!/bin/bash /home/aistudio/work/astar2019/testssd.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、量化、剪枝操作\n",
    "### 2.1 剪枝、量化操作\n",
    "加载前一步骤训练保存的infer模型，进行剪枝、量化操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.1 图像预处理工具`image_util`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image_util\n",
    "from PIL import Image, ImageEnhance, ImageDraw\n",
    "from PIL import ImageFile\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  #otherwise IOError raised image file is truncated\n",
    "\n",
    "\n",
    "class sampler():\n",
    "    def __init__(self, max_sample, max_trial, min_scale, max_scale,\n",
    "                 min_aspect_ratio, max_aspect_ratio, min_jaccard_overlap,\n",
    "                 max_jaccard_overlap):\n",
    "        self.max_sample = max_sample\n",
    "        self.max_trial = max_trial\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.min_aspect_ratio = min_aspect_ratio\n",
    "        self.max_aspect_ratio = max_aspect_ratio\n",
    "        self.min_jaccard_overlap = min_jaccard_overlap\n",
    "        self.max_jaccard_overlap = max_jaccard_overlap\n",
    "\n",
    "\n",
    "class bbox():\n",
    "    def __init__(self, xmin, ymin, xmax, ymax):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "\n",
    "\n",
    "def bbox_area(src_bbox):\n",
    "    width = src_bbox.xmax - src_bbox.xmin\n",
    "    height = src_bbox.ymax - src_bbox.ymin\n",
    "    return width * height\n",
    "\n",
    "\n",
    "def generate_sample(sampler):\n",
    "    scale = np.random.uniform(sampler.min_scale, sampler.max_scale)\n",
    "    aspect_ratio = np.random.uniform(sampler.min_aspect_ratio,\n",
    "                                  sampler.max_aspect_ratio)\n",
    "    aspect_ratio = max(aspect_ratio, (scale**2.0))\n",
    "    aspect_ratio = min(aspect_ratio, 1 / (scale**2.0))\n",
    "\n",
    "    bbox_width = scale * (aspect_ratio**0.5)\n",
    "    bbox_height = scale / (aspect_ratio**0.5)\n",
    "    xmin_bound = 1 - bbox_width\n",
    "    ymin_bound = 1 - bbox_height\n",
    "    xmin = np.random.uniform(0, xmin_bound)\n",
    "    ymin = np.random.uniform(0, ymin_bound)\n",
    "    xmax = xmin + bbox_width\n",
    "    ymax = ymin + bbox_height\n",
    "    sampled_bbox = bbox(xmin, ymin, xmax, ymax)\n",
    "    return sampled_bbox\n",
    "\n",
    "\n",
    "def jaccard_overlap(sample_bbox, object_bbox):\n",
    "    if sample_bbox.xmin >= object_bbox.xmax or \\\n",
    "            sample_bbox.xmax <= object_bbox.xmin or \\\n",
    "            sample_bbox.ymin >= object_bbox.ymax or \\\n",
    "            sample_bbox.ymax <= object_bbox.ymin:\n",
    "        return 0\n",
    "    intersect_xmin = max(sample_bbox.xmin, object_bbox.xmin)\n",
    "    intersect_ymin = max(sample_bbox.ymin, object_bbox.ymin)\n",
    "    intersect_xmax = min(sample_bbox.xmax, object_bbox.xmax)\n",
    "    intersect_ymax = min(sample_bbox.ymax, object_bbox.ymax)\n",
    "    intersect_size = (intersect_xmax - intersect_xmin) * (\n",
    "        intersect_ymax - intersect_ymin)\n",
    "    sample_bbox_size = bbox_area(sample_bbox)\n",
    "    object_bbox_size = bbox_area(object_bbox)\n",
    "    overlap = intersect_size / (\n",
    "        sample_bbox_size + object_bbox_size - intersect_size)\n",
    "    return overlap\n",
    "\n",
    "\n",
    "def satisfy_sample_constraint(sampler, sample_bbox, bbox_labels):\n",
    "    if sampler.min_jaccard_overlap == 0 and sampler.max_jaccard_overlap == 0:\n",
    "        return True\n",
    "    for i in range(len(bbox_labels)):\n",
    "        object_bbox = bbox(bbox_labels[i][1], bbox_labels[i][2],\n",
    "                           bbox_labels[i][3], bbox_labels[i][4])\n",
    "        overlap = jaccard_overlap(sample_bbox, object_bbox)\n",
    "        if sampler.min_jaccard_overlap != 0 and \\\n",
    "                overlap < sampler.min_jaccard_overlap:\n",
    "            continue\n",
    "        if sampler.max_jaccard_overlap != 0 and \\\n",
    "                overlap > sampler.max_jaccard_overlap:\n",
    "            continue\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def generate_batch_samples(batch_sampler, bbox_labels):\n",
    "    sampled_bbox = []\n",
    "    index = []\n",
    "    c = 0\n",
    "    for sampler in batch_sampler:\n",
    "        found = 0\n",
    "        for i in range(sampler.max_trial):\n",
    "            if found >= sampler.max_sample:\n",
    "                break\n",
    "            sample_bbox = generate_sample(sampler)\n",
    "            if satisfy_sample_constraint(sampler, sample_bbox, bbox_labels):\n",
    "                sampled_bbox.append(sample_bbox)\n",
    "                found = found + 1\n",
    "                index.append(c)\n",
    "        c = c + 1\n",
    "    return sampled_bbox\n",
    "\n",
    "\n",
    "def clip_bbox(src_bbox):\n",
    "    src_bbox.xmin = max(min(src_bbox.xmin, 1.0), 0.0)\n",
    "    src_bbox.ymin = max(min(src_bbox.ymin, 1.0), 0.0)\n",
    "    src_bbox.xmax = max(min(src_bbox.xmax, 1.0), 0.0)\n",
    "    src_bbox.ymax = max(min(src_bbox.ymax, 1.0), 0.0)\n",
    "    return src_bbox\n",
    "\n",
    "\n",
    "def meet_emit_constraint(src_bbox, sample_bbox):\n",
    "    center_x = (src_bbox.xmax + src_bbox.xmin) / 2\n",
    "    center_y = (src_bbox.ymax + src_bbox.ymin) / 2\n",
    "    if center_x >= sample_bbox.xmin and \\\n",
    "        center_x <= sample_bbox.xmax and \\\n",
    "        center_y >= sample_bbox.ymin and \\\n",
    "        center_y <= sample_bbox.ymax:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def transform_labels(bbox_labels, sample_bbox):\n",
    "    proj_bbox = bbox(0, 0, 0, 0)\n",
    "    sample_labels = []\n",
    "    for i in range(len(bbox_labels)):\n",
    "        sample_label = []\n",
    "        object_bbox = bbox(bbox_labels[i][1], bbox_labels[i][2],\n",
    "                           bbox_labels[i][3], bbox_labels[i][4])\n",
    "        if not meet_emit_constraint(object_bbox, sample_bbox):\n",
    "            continue\n",
    "        sample_width = sample_bbox.xmax - sample_bbox.xmin\n",
    "        sample_height = sample_bbox.ymax - sample_bbox.ymin\n",
    "        proj_bbox.xmin = (object_bbox.xmin - sample_bbox.xmin) / sample_width\n",
    "        proj_bbox.ymin = (object_bbox.ymin - sample_bbox.ymin) / sample_height\n",
    "        proj_bbox.xmax = (object_bbox.xmax - sample_bbox.xmin) / sample_width\n",
    "        proj_bbox.ymax = (object_bbox.ymax - sample_bbox.ymin) / sample_height\n",
    "        proj_bbox = clip_bbox(proj_bbox)\n",
    "        if bbox_area(proj_bbox) > 0:\n",
    "            sample_label.append(bbox_labels[i][0])\n",
    "            sample_label.append(float(proj_bbox.xmin))\n",
    "            sample_label.append(float(proj_bbox.ymin))\n",
    "            sample_label.append(float(proj_bbox.xmax))\n",
    "            sample_label.append(float(proj_bbox.ymax))\n",
    "            #sample_label.append(bbox_labels[i][5])\n",
    "            sample_label = sample_label + bbox_labels[i][5:]\n",
    "            sample_labels.append(sample_label)\n",
    "    return sample_labels\n",
    "\n",
    "\n",
    "def crop_image(img, bbox_labels, sample_bbox, image_width, image_height):\n",
    "    sample_bbox = clip_bbox(sample_bbox)\n",
    "    xmin = int(sample_bbox.xmin * image_width)\n",
    "    xmax = int(sample_bbox.xmax * image_width)\n",
    "    ymin = int(sample_bbox.ymin * image_height)\n",
    "    ymax = int(sample_bbox.ymax * image_height)\n",
    "    sample_img = img[ymin:ymax, xmin:xmax]\n",
    "    sample_labels = transform_labels(bbox_labels, sample_bbox)\n",
    "    return sample_img, sample_labels\n",
    "\n",
    "\n",
    "def random_brightness(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._brightness_prob:\n",
    "        delta = np.random.uniform(-settings._brightness_delta,\n",
    "                               settings._brightness_delta) + 1\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_contrast(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._contrast_prob:\n",
    "        delta = np.random.uniform(-settings._contrast_delta,\n",
    "                               settings._contrast_delta) + 1\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_saturation(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._saturation_prob:\n",
    "        delta = np.random.uniform(-settings._saturation_delta,\n",
    "                               settings._saturation_delta) + 1\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_hue(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._hue_prob:\n",
    "        delta = np.random.uniform(-settings._hue_delta, settings._hue_delta)\n",
    "        img_hsv = np.array(img.convert('HSV'))\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "def distort_image(img, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    # Apply different distort order\n",
    "    if prob > 0.5:\n",
    "        img = random_brightness(img, settings)\n",
    "        img = random_contrast(img, settings)\n",
    "        img = random_saturation(img, settings)\n",
    "        img = random_hue(img, settings)\n",
    "    else:\n",
    "        img = random_brightness(img, settings)\n",
    "        img = random_saturation(img, settings)\n",
    "        img = random_hue(img, settings)\n",
    "        img = random_contrast(img, settings)\n",
    "    return img\n",
    "\n",
    "\n",
    "def expand_image(img, bbox_labels, img_width, img_height, settings):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < settings._expand_prob:\n",
    "        if settings._expand_max_ratio - 1 >= 0.01:\n",
    "            expand_ratio = np.random.uniform(1, settings._expand_max_ratio)\n",
    "            height = int(img_height * expand_ratio)\n",
    "            width = int(img_width * expand_ratio)\n",
    "            h_off = math.floor(np.random.uniform(0, height - img_height))\n",
    "            w_off = math.floor(np.random.uniform(0, width - img_width))\n",
    "            expand_bbox = bbox(-w_off / img_width, -h_off / img_height,\n",
    "                               (width - w_off) / img_width,\n",
    "                               (height - h_off) / img_height)\n",
    "            expand_img = np.ones((height, width, 3))\n",
    "            expand_img = np.uint8(expand_img * np.squeeze(settings._img_mean))\n",
    "            expand_img = Image.fromarray(expand_img)\n",
    "            expand_img.paste(img, (int(w_off), int(h_off)))\n",
    "            bbox_labels = transform_labels(bbox_labels, expand_bbox)\n",
    "            return expand_img, bbox_labels, width, height\n",
    "    return img, bbox_labels, img_width, img_height\n",
    "\n",
    "class Settings(object):\n",
    "    def __init__(self,\n",
    "                 dataset=None,\n",
    "                 data_dir=None,\n",
    "                 label_file=None,\n",
    "                 resize_h=300,\n",
    "                 resize_w=300,\n",
    "                 mean_value=[127.5, 127.5, 127.5],\n",
    "                 apply_distort=True,\n",
    "                 apply_expand=True,\n",
    "                 ap_version='11point'):\n",
    "        self._dataset = dataset\n",
    "        self._ap_version = ap_version\n",
    "        self._data_dir = data_dir\n",
    "        if 'pascalvoc' in dataset:\n",
    "            self._label_list = []\n",
    "            label_fpath = os.path.join(data_dir, label_file)\n",
    "            for line in open(label_fpath):\n",
    "                self._label_list.append(line.strip())\n",
    "\n",
    "        self._apply_distort = apply_distort\n",
    "        self._apply_expand = apply_expand\n",
    "        self._resize_height = resize_h\n",
    "        self._resize_width = resize_w\n",
    "        self._img_mean = np.array(mean_value)[:, np.newaxis, np.newaxis].astype(\n",
    "            'float32')\n",
    "        self._expand_prob = 0.5\n",
    "        self._expand_max_ratio = 4\n",
    "        self._hue_prob = 0.5\n",
    "        self._hue_delta = 18\n",
    "        self._contrast_prob = 0.5\n",
    "        self._contrast_delta = 0.5\n",
    "        self._saturation_prob = 0.5\n",
    "        self._saturation_delta = 0.5\n",
    "        self._brightness_prob = 0.5\n",
    "        self._brightness_delta = 0.125\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset\n",
    "\n",
    "    @property\n",
    "    def ap_version(self):\n",
    "        return self._ap_version\n",
    "\n",
    "    @property\n",
    "    def apply_distort(self):\n",
    "        return self._apply_expand\n",
    "\n",
    "    @property\n",
    "    def apply_distort(self):\n",
    "        return self._apply_distort\n",
    "\n",
    "    @property\n",
    "    def data_dir(self):\n",
    "        return self._data_dir\n",
    "\n",
    "    @data_dir.setter\n",
    "    def data_dir(self, data_dir):\n",
    "        self._data_dir = data_dir\n",
    "\n",
    "    @property\n",
    "    def label_list(self):\n",
    "        return self._label_list\n",
    "\n",
    "    @property\n",
    "    def resize_h(self):\n",
    "        return self._resize_height\n",
    "\n",
    "    @property\n",
    "    def resize_w(self):\n",
    "        return self._resize_width\n",
    "\n",
    "    @property\n",
    "    def img_mean(self):\n",
    "        return self._img_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.2 设置全局变量参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args_image_shape = '3,300,300'\n",
    "args_mean_BGR = '127.5,127.5,127.5'\n",
    "args_data_dir = '/home/aistudio/work/coco2017'\n",
    "args_dataset = 'coco2017'\n",
    "#预剪枝、量化的模型路径\n",
    "args_pretrained_model = '/home/aistudio/work/models/infer_models/best_models_submit_20190914_best/'\n",
    "# args_pretrained_model = '/home/aistudio/work/models_20190824/infer_models/best_models_submit_20190822/'\n",
    "args_ap_version = '11point'\n",
    "\n",
    "\n",
    "data_dir = args_data_dir\n",
    "dataset = args_dataset\n",
    "assert dataset in ['pascalvoc', 'coco2014', 'coco2017']\n",
    "\n",
    "# for pascalvoc\n",
    "label_file = 'label_list'\n",
    "train_file_list = 'trainval.txt'\n",
    "val_file_list = 'test.txt'\n",
    "\n",
    "if dataset == 'coco2014':\n",
    "    train_file_list = 'annotations/instances_train2014.json'\n",
    "    val_file_list = 'annotations/instances_val2014.json'\n",
    "elif dataset == 'coco2017':\n",
    "    train_file_list = 'annotations/instances_train2017.json'\n",
    "    val_file_list = 'annotations/instances_val2017.json'\n",
    "\n",
    "mean_BGR = [float(m) for m in args_mean_BGR.split(\",\")]\n",
    "image_shape = [int(m) for m in args_image_shape.split(\",\")]\n",
    "\n",
    "data_args = Settings(\n",
    "dataset=args_dataset,\n",
    "data_dir=data_dir,\n",
    "label_file=label_file,\n",
    "resize_h=image_shape[1],\n",
    "resize_w=image_shape[2],\n",
    "mean_value=mean_BGR,\n",
    "apply_distort=True,\n",
    "apply_expand=True,\n",
    "ap_version = args_ap_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.3 数据读取`reader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import six\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import paddle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(img, bbox_labels, mode, settings):\n",
    "    img_width, img_height = img.size\n",
    "    sampled_labels = bbox_labels\n",
    "    if mode == 'train':\n",
    "        if settings._apply_distort:\n",
    "            img = distort_image(img, settings)\n",
    "        if settings._apply_expand:\n",
    "            img, bbox_labels, img_width, img_height = expand_image(\n",
    "                img, bbox_labels, img_width, img_height, settings)\n",
    "        # sampling\n",
    "        batch_sampler = []\n",
    "        # hard-code here\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 1, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.1, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.3, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.5, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.7, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.9, 0.0))\n",
    "        batch_sampler.append(\n",
    "            sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.0, 1.0))\n",
    "        sampled_bbox = generate_batch_samples(batch_sampler,\n",
    "                                                         bbox_labels)\n",
    "\n",
    "        img = np.array(img)\n",
    "        if len(sampled_bbox) > 0:\n",
    "            idx = int(np.random.uniform(0, len(sampled_bbox)))\n",
    "            img, sampled_labels = crop_image(\n",
    "                img, bbox_labels, sampled_bbox[idx], img_width, img_height)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "    img = img.resize((settings.resize_w, settings.resize_h), Image.ANTIALIAS)\n",
    "    img = np.array(img)\n",
    "\n",
    "    if mode == 'train':\n",
    "        mirror = int(np.random.uniform(0, 2))\n",
    "        if mirror == 1:\n",
    "            img = img[:, ::-1, :]\n",
    "            for i in six.moves.xrange(len(sampled_labels)):\n",
    "                tmp = sampled_labels[i][1]\n",
    "                sampled_labels[i][1] = 1 - sampled_labels[i][3]\n",
    "                sampled_labels[i][3] = 1 - tmp\n",
    "    # HWC to CHW\n",
    "    if len(img.shape) == 3:\n",
    "        img = np.swapaxes(img, 1, 2)\n",
    "        img = np.swapaxes(img, 1, 0)\n",
    "    # RBG to BGR\n",
    "    img = img[[2, 1, 0], :, :]\n",
    "    img = img.astype('float32')\n",
    "    img -= settings.img_mean\n",
    "    img = img * 0.007843\n",
    "    return img, sampled_labels\n",
    "\n",
    "\n",
    "def coco(settings, coco_api, file_list, mode, batch_size, shuffle, data_dir):\n",
    "    from pycocotools.coco import COCO\n",
    "\n",
    "    json_category_id_to_contiguous_id = {\n",
    "        v: i + 1\n",
    "        for i, v in enumerate(coco_api.getCatIds())\n",
    "    }\n",
    "    contiguous_category_id_to_json_id = {\n",
    "        v: k\n",
    "        for k, v in json_category_id_to_contiguous_id.items()\n",
    "    }\n",
    "    def reader():\n",
    "        if mode == 'train' and shuffle:\n",
    "            np.random.shuffle(file_list)\n",
    "        batch_out = []\n",
    "        for image in file_list:\n",
    "            image_name = image['file_name']\n",
    "            image_path = os.path.join(data_dir, image_name)\n",
    "            if not os.path.exists(image_path):\n",
    "                raise ValueError(\"%s is not exist, you should specify \"\n",
    "                                 \"data path correctly.\" % image_path)\n",
    "            im = Image.open(image_path)\n",
    "            if im.mode == 'L':\n",
    "                im = im.convert('RGB')\n",
    "            im_width, im_height = im.size\n",
    "            im_id = image['id']\n",
    "\n",
    "            # layout: category_id | xmin | ymin | xmax | ymax | iscrowd\n",
    "            bbox_labels = []\n",
    "            annIds = coco_api.getAnnIds(imgIds=image['id'])\n",
    "            anns = coco_api.loadAnns(annIds)\n",
    "            for ann in anns:\n",
    "                bbox_sample = []\n",
    "                # start from 1, leave 0 to background\n",
    "                # bbox_sample.append(float(ann['category_id']))\n",
    "                bbox_sample.append(float(json_category_id_to_contiguous_id[ann['category_id']]))\n",
    "                bbox = ann['bbox']\n",
    "                xmin, ymin, w, h = bbox\n",
    "                xmax = xmin + w\n",
    "                ymax = ymin + h\n",
    "                bbox_sample.append(float(xmin) / im_width)\n",
    "                bbox_sample.append(float(ymin) / im_height)\n",
    "                bbox_sample.append(float(xmax) / im_width)\n",
    "                bbox_sample.append(float(ymax) / im_height)\n",
    "                bbox_sample.append(float(ann['iscrowd']))\n",
    "                bbox_labels.append(bbox_sample)\n",
    "            im, sample_labels = preprocess(im, bbox_labels, mode, settings)\n",
    "            sample_labels = np.array(sample_labels)\n",
    "            if len(sample_labels) == 0: continue\n",
    "            im = im.astype('float32')\n",
    "            boxes = sample_labels[:, 1:5]\n",
    "            lbls = sample_labels[:, 0].astype('int32')\n",
    "            iscrowd = sample_labels[:, -1].astype('int32')\n",
    "            if 'cocoMAP' in settings.ap_version:\n",
    "                batch_out.append((im, boxes, lbls, iscrowd,\n",
    "                                  [im_id, im_width, im_height]))\n",
    "            else:\n",
    "                batch_out.append((im, boxes, lbls, iscrowd))\n",
    "\n",
    "            if len(batch_out) == batch_size:\n",
    "                yield batch_out\n",
    "                batch_out = []\n",
    "\n",
    "        if mode == 'test' and len(batch_out) > 1:\n",
    "            yield batch_out\n",
    "            batch_out = []\n",
    "\n",
    "    return reader\n",
    "\n",
    "\n",
    "def pascalvoc(settings, file_list, mode, batch_size, shuffle):\n",
    "    def reader():\n",
    "        if mode == 'train' and shuffle:\n",
    "            np.random.shuffle(file_list)\n",
    "        batch_out = []\n",
    "        cnt = 0\n",
    "        for image in file_list:\n",
    "            image_path, label_path = image.split()\n",
    "            image_path = os.path.join(settings.data_dir, image_path)\n",
    "            label_path = os.path.join(settings.data_dir, label_path)\n",
    "            if not os.path.exists(image_path):\n",
    "                raise ValueError(\"%s is not exist, you should specify \"\n",
    "                                 \"data path correctly.\" % image_path)\n",
    "            im = Image.open(image_path)\n",
    "            if im.mode == 'L':\n",
    "                im = im.convert('RGB')\n",
    "            im_width, im_height = im.size\n",
    "\n",
    "            # layout: label | xmin | ymin | xmax | ymax | difficult\n",
    "            bbox_labels = []\n",
    "            root = xml.etree.ElementTree.parse(label_path).getroot()\n",
    "            for object in root.findall('object'):\n",
    "                bbox_sample = []\n",
    "                # start from 1\n",
    "                bbox_sample.append(\n",
    "                    float(settings.label_list.index(object.find('name').text)))\n",
    "                bbox = object.find('bndbox')\n",
    "                difficult = float(object.find('difficult').text)\n",
    "                bbox_sample.append(float(bbox.find('xmin').text) / im_width)\n",
    "                bbox_sample.append(float(bbox.find('ymin').text) / im_height)\n",
    "                bbox_sample.append(float(bbox.find('xmax').text) / im_width)\n",
    "                bbox_sample.append(float(bbox.find('ymax').text) / im_height)\n",
    "                bbox_sample.append(difficult)\n",
    "                bbox_labels.append(bbox_sample)\n",
    "            im, sample_labels = preprocess(im, bbox_labels, mode, settings)\n",
    "            sample_labels = np.array(sample_labels)\n",
    "            if len(sample_labels) == 0: continue\n",
    "            im = im.astype('float32')\n",
    "            boxes = sample_labels[:, 1:5]\n",
    "            lbls = sample_labels[:, 0].astype('int32')\n",
    "            difficults = sample_labels[:, -1].astype('int32')\n",
    "\n",
    "            batch_out.append((im, boxes, lbls, difficults))\n",
    "            if len(batch_out) == batch_size:\n",
    "                yield batch_out\n",
    "                cnt += len(batch_out)\n",
    "                batch_out = []\n",
    "\n",
    "        if mode == 'test' and len(batch_out) > 1:\n",
    "            yield batch_out\n",
    "            cnt += len(batch_out)\n",
    "            batch_out = []\n",
    "\n",
    "    return reader\n",
    "\n",
    "\n",
    "def train_data_reader(settings,\n",
    "          file_list,\n",
    "          batch_size,\n",
    "          shuffle=True,\n",
    "          use_multiprocess=True,\n",
    "          num_workers=8,\n",
    "          enable_ce=False):\n",
    "    file_path = os.path.join(settings.data_dir, file_list)\n",
    "    readers = []\n",
    "    if 'coco' in settings.dataset:\n",
    "        # cocoapi\n",
    "        from pycocotools.coco import COCO\n",
    "        coco_api = COCO(file_path)\n",
    "        image_ids = coco_api.getImgIds()\n",
    "        images = coco_api.loadImgs(image_ids)\n",
    "        np.random.shuffle(images)\n",
    "        if '2014' in file_list:\n",
    "            sub_dir = \"train2014\"\n",
    "        elif '2017' in file_list:\n",
    "            sub_dir = \"train2017\"\n",
    "        data_dir = os.path.join(settings.data_dir, sub_dir)\n",
    "        print(\"data_dir:{}\".format(data_dir))\n",
    "        n = int(math.ceil(len(images) // num_workers)) if use_multiprocess \\\n",
    "            else len(images)\n",
    "        image_lists = [images[i:i + n] for i in range(0, len(images), n)]\n",
    "        for l in image_lists:\n",
    "            readers.append(\n",
    "                coco(settings, coco_api, l, 'train', batch_size, shuffle,\n",
    "                     data_dir))\n",
    "    else:\n",
    "        images = [line.strip() for line in open(file_path)]\n",
    "        np.random.shuffle(images)\n",
    "        n = int(math.ceil(len(images) // num_workers)) if use_multiprocess \\\n",
    "            else len(images)\n",
    "        image_lists = [images[i:i + n] for i in range(0, len(images), n)]\n",
    "        for l in image_lists:\n",
    "            readers.append(pascalvoc(settings, l, 'train', batch_size, shuffle))\n",
    "    print(\"use_multiprocess \", use_multiprocess)\n",
    "    if use_multiprocess:\n",
    "        return paddle.reader.multiprocess_reader(readers, False)\n",
    "    else:\n",
    "        return readers[0]\n",
    "    #     n = int(math.ceil(len(images) // num_workers))\n",
    "    #     image_lists = [images[i:i + n] for i in range(0, len(images), n)]\n",
    "\n",
    "    #     if '2014' in file_list:\n",
    "    #         sub_dir = \"train2014\"\n",
    "    #     elif '2017' in file_list:\n",
    "    #         sub_dir = \"train2017\"\n",
    "    #     data_dir = os.path.join(settings.data_dir, sub_dir)\n",
    "    #     for l in image_lists:\n",
    "    #         readers.append(\n",
    "    #             coco(settings, coco_api, l, 'train', batch_size, shuffle,\n",
    "    #                  data_dir))\n",
    "    # else:\n",
    "    #     images = [line.strip() for line in open(file_path)]\n",
    "    #     n = int(math.ceil(len(images) // num_workers))\n",
    "    #     image_lists = [images[i:i + n] for i in range(0, len(images), n)]\n",
    "    #     for l in image_lists:\n",
    "    #         readers.append(pascalvoc(settings, l, 'train', batch_size, shuffle))\n",
    "\n",
    "    # return paddle.reader.multiprocess_reader(readers, False)\n",
    "\n",
    "\n",
    "def test_data_reader(settings, file_list, batch_size):\n",
    "    file_list = os.path.join(settings.data_dir, file_list)\n",
    "    if 'coco' in settings.dataset:\n",
    "        from pycocotools.coco import COCO\n",
    "        coco_api = COCO(file_list)\n",
    "        image_ids = coco_api.getImgIds()\n",
    "        images = coco_api.loadImgs(image_ids)\n",
    "        if '2014' in file_list:\n",
    "            sub_dir = \"val2014\"\n",
    "        elif '2017' in file_list:\n",
    "            sub_dir = \"val2017\"\n",
    "        data_dir = os.path.join(settings.data_dir, sub_dir)\n",
    "        return coco(settings, coco_api, images, 'test', batch_size, False,\n",
    "                    data_dir)\n",
    "    else:\n",
    "        image_list = [line.strip() for line in open(file_list)]\n",
    "        return pascalvoc(settings, image_list, 'test', batch_size, False)\n",
    "\n",
    "\n",
    "def infer(settings, image_path):\n",
    "    def reader():\n",
    "        if not os.path.exists(image_path):\n",
    "            raise ValueError(\"%s is not exist, you should specify \"\n",
    "                             \"data path correctly.\" % image_path)\n",
    "        img = Image.open(image_path)\n",
    "        if img.mode == 'L':\n",
    "            img = img.convert('RGB')\n",
    "        im_width, im_height = img.size\n",
    "        img = img.resize((settings.resize_w, settings.resize_h),\n",
    "                         Image.ANTIALIAS)\n",
    "        img = np.array(img)\n",
    "        # HWC to CHW\n",
    "        if len(img.shape) == 3:\n",
    "            img = np.swapaxes(img, 1, 2)\n",
    "            img = np.swapaxes(img, 1, 0)\n",
    "        # RBG to BGR\n",
    "        img = img[[2, 1, 0], :, :]\n",
    "        img = img.astype('float32')\n",
    "        img -= settings.img_mean\n",
    "        img = img * 0.007843\n",
    "        return img\n",
    "\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.4 定义网络结构`mobilenet v1 ssd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.initializer import MSRA\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "\n",
    "\n",
    "def conv_bn(input,\n",
    "            filter_size,\n",
    "            num_filters,\n",
    "            stride,\n",
    "            padding,\n",
    "            channels=None,\n",
    "            num_groups=1,\n",
    "            act='relu',\n",
    "            use_cudnn=True,\n",
    "            name=None):\n",
    "    parameter_attr = ParamAttr(learning_rate=0.1, initializer=MSRA())\n",
    "    conv = fluid.layers.conv2d(\n",
    "        input=input,\n",
    "        num_filters=num_filters,\n",
    "        filter_size=filter_size,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        groups=num_groups,\n",
    "        act=None,\n",
    "        use_cudnn=use_cudnn,\n",
    "        param_attr=parameter_attr,\n",
    "        bias_attr=False)\n",
    "    return fluid.layers.batch_norm(input=conv, act=act)\n",
    "\n",
    "\n",
    "def depthwise_separable(input, num_filters1, num_filters2, num_groups, stride,\n",
    "                        scale):\n",
    "    depthwise_conv = conv_bn(\n",
    "        input=input,\n",
    "        filter_size=3,\n",
    "        num_filters=int(num_filters1 * scale),\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        num_groups=int(num_groups * scale),\n",
    "        use_cudnn=False)\n",
    "\n",
    "    pointwise_conv = conv_bn(\n",
    "        input=depthwise_conv,\n",
    "        filter_size=1,\n",
    "        num_filters=int(num_filters2 * scale),\n",
    "        stride=1,\n",
    "        padding=0)\n",
    "    return pointwise_conv\n",
    "\n",
    "\n",
    "def extra_block(input, num_filters1, num_filters2, num_groups, stride, scale):\n",
    "    # 1x1 conv\n",
    "    pointwise_conv = conv_bn(\n",
    "        input=input,\n",
    "        filter_size=1,\n",
    "        num_filters=int(num_filters1 * scale),\n",
    "        stride=1,\n",
    "        num_groups=int(num_groups * scale),\n",
    "        padding=0)\n",
    "\n",
    "    # 3x3 conv\n",
    "    normal_conv = conv_bn(\n",
    "        input=pointwise_conv,\n",
    "        filter_size=3,\n",
    "        num_filters=int(num_filters2 * scale),\n",
    "        stride=2,\n",
    "        num_groups=int(num_groups * scale),\n",
    "        padding=1)\n",
    "    return normal_conv\n",
    "\n",
    "\n",
    "def mobile_net(num_classes, img, img_shape, scale=1.0):\n",
    "    # 300x300\n",
    "    tmp = conv_bn(img, 3, int(32 * scale), 2, 1, 3)\n",
    "    # 150x150\n",
    "    tmp = depthwise_separable(tmp, 32, 64, 32, 1, scale)\n",
    "    tmp = depthwise_separable(tmp, 64, 128, 64, 2, scale)\n",
    "    # 75x75\n",
    "    tmp = depthwise_separable(tmp, 128, 128, 128, 1, scale)\n",
    "    tmp = depthwise_separable(tmp, 128, 256, 128, 2, scale)\n",
    "    # 38x38\n",
    "    tmp = depthwise_separable(tmp, 256, 256, 256, 1, scale)\n",
    "    tmp = depthwise_separable(tmp, 256, 512, 256, 2, scale)\n",
    "\n",
    "    # 19x19\n",
    "    for i in range(5):\n",
    "        tmp = depthwise_separable(tmp, 512, 512, 512, 1, scale)\n",
    "    module11 = tmp\n",
    "    tmp = depthwise_separable(tmp, 512, 1024, 512, 2, scale)\n",
    "\n",
    "    # 10x10\n",
    "    module13 = depthwise_separable(tmp, 1024, 1024, 1024, 1, scale)\n",
    "    module14 = extra_block(module13, 256, 512, 1, 2, scale)\n",
    "    # 5x5\n",
    "    module15 = extra_block(module14, 128, 256, 1, 2, scale)\n",
    "    # 3x3\n",
    "    module16 = extra_block(module15, 128, 256, 1, 2, scale)\n",
    "    # 2x2\n",
    "    module17 = extra_block(module16, 64, 128, 1, 2, scale)\n",
    "\n",
    "    mbox_locs, mbox_confs, box, box_var = fluid.layers.multi_box_head(\n",
    "        inputs=[module11, module13, module14, module15, module16, module17],\n",
    "        image=img,\n",
    "        num_classes=num_classes,\n",
    "        min_ratio=20,\n",
    "        max_ratio=90,\n",
    "        min_sizes=[60.0, 105.0, 150.0, 195.0, 240.0, 285.0],\n",
    "        max_sizes=[[], 150.0, 195.0, 240.0, 285.0, 300.0],\n",
    "        aspect_ratios=[[2.], [2., 3.], [2., 3.], [2., 3.], [2., 3.], [2., 3.]],\n",
    "        base_size=img_shape[2],\n",
    "        offset=0.5,\n",
    "        flip=True)\n",
    "\n",
    "    return mbox_locs, mbox_confs, box, box_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.5 自定义网络结构`mobilenet v2 ssd`，（训练loss降不下去，效果不好）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from paddle.fluid.initializer import MSRA\n",
    "# from paddle.fluid.param_attr import ParamAttr\n",
    "\n",
    "# class MobileNetV2SSD():\n",
    "#     def __init__(self, img, num_classes, img_shape, change_depth=False):\n",
    "#         self.img = img\n",
    "#         self.num_classes = num_classes\n",
    "#         self.img_shape = img_shape\n",
    "#         self.change_depth = change_depth\n",
    "\n",
    "#     def net(self, scale=1.0):\n",
    "#         change_depth = self.change_depth\n",
    "#         # if change_depth is True, the new depth is 1.4 times as deep as before.\n",
    "#         bottleneck_params_list = [\n",
    "#             (1, 16, 1, 1),\n",
    "#             (6, 24, 2, 2),\n",
    "#             (6, 32, 3, 2),\n",
    "#             (6, 64, 4, 2),\n",
    "#             (6, 96, 3, 1),\n",
    "#             (6, 160, 3, 2),\n",
    "#             (6, 320, 1, 1),\n",
    "#         ] if change_depth == False else [\n",
    "#             (1, 16, 1, 1),\n",
    "#             (6, 24, 2, 2),\n",
    "#             (6, 32, 5, 2),\n",
    "#             (6, 64, 7, 2),\n",
    "#             (6, 96, 5, 1),\n",
    "#             (6, 160, 3, 2),\n",
    "#             (6, 320, 1, 1),\n",
    "#         ]\n",
    "\n",
    "#         # conv1\n",
    "#         input = self.conv_bn_layer(\n",
    "#             self.img,\n",
    "#             num_filters=int(32 * scale),\n",
    "#             filter_size=3,\n",
    "#             stride=2,\n",
    "#             padding=1,\n",
    "#             if_act=True,\n",
    "#             name='conv1_1')\n",
    "\n",
    "#         # bottleneck sequences\n",
    "#         i = 1\n",
    "#         in_c = int(32 * scale)\n",
    "#         module11 = None\n",
    "#         for layer_setting in bottleneck_params_list:\n",
    "#             t, c, n, s = layer_setting\n",
    "#             i += 1\n",
    "#             input = self.invresi_blocks(\n",
    "#                 input=input,\n",
    "#                 in_c=in_c,\n",
    "#                 t=t,\n",
    "#                 c=int(c * scale),\n",
    "#                 n=n,\n",
    "#                 s=s,\n",
    "#                 name='conv' + str(i))\n",
    "#             if i==6:\n",
    "#                 # 19x19\n",
    "#                 module11 = self.conv_bn_layer(input=input,num_filters=512,filter_size=1,stride=1,padding=0,if_act=True,name='ssd1')\n",
    "#             in_c = int(c * scale)\n",
    "#         # last_conv\n",
    "#         tmp = self.conv_bn_layer(\n",
    "#             input=input,\n",
    "#             num_filters=int(1280 * scale) if scale > 1.0 else 1280,\n",
    "#             filter_size=1,\n",
    "#             stride=1,\n",
    "#             padding=0,\n",
    "#             if_act=True,\n",
    "#             name='conv9')\n",
    "#         module13 = self.conv_bn_layer(input=tmp,num_filters=1024,filter_size=1,stride=1,padding=0,if_act=True,name='ssd2')\n",
    "#         # 10x10\n",
    "#         module14 = self.extra_block(module13, 256, 512, 1, 2, scale)\n",
    "#         # 5x5\n",
    "#         module15 = self.extra_block(module14, 128, 256, 1, 2, scale)\n",
    "#         # 3x3\n",
    "#         module16 = self.extra_block(module15, 128, 256, 1, 2, scale)\n",
    "#         # 2x2\n",
    "#         module17 = self.extra_block(module16, 64, 128, 1, 2, scale)\n",
    "\n",
    "#         # mbox_locs：预测的输入框的位置\n",
    "#         # mbox_confs：预测框对输入的置信度\n",
    "#         # box：PriorBox输出的先验框\n",
    "#         # box_var：PriorBox的扩展方差\n",
    "#         mbox_locs, mbox_confs, box, box_var = fluid.layers.multi_box_head(\n",
    "#             inputs=[\n",
    "#                 module11, module13, module14, module15, module16, module17\n",
    "#             ],\n",
    "#             image=self.img,\n",
    "#             num_classes=self.num_classes,\n",
    "#             min_ratio=20,\n",
    "#             max_ratio=90,\n",
    "#             min_sizes=[60.0, 105.0, 150.0, 195.0, 240.0, 285.0],\n",
    "#             max_sizes=[[], 150.0, 195.0, 240.0, 285.0, 300.0],\n",
    "#             aspect_ratios=[[2.], [2., 3.], [2., 3.], [2., 3.], [2., 3.],\n",
    "#                           [2., 3.]],\n",
    "#             base_size=self.img_shape[2],\n",
    "#             offset=0.5,\n",
    "#             flip=True)\n",
    "\n",
    "#         return mbox_locs, mbox_confs, box, box_var\n",
    "\n",
    "#     def conv_bn_layer(self,\n",
    "#                       input,\n",
    "#                       filter_size,\n",
    "#                       num_filters,\n",
    "#                       stride,\n",
    "#                       padding,\n",
    "#                       channels=None,\n",
    "#                       num_groups=1,\n",
    "#                       if_act=True,\n",
    "#                       name=None,\n",
    "#                       use_cudnn=True):\n",
    "#         conv = fluid.layers.conv2d(\n",
    "#             input=input,\n",
    "#             num_filters=num_filters,\n",
    "#             filter_size=filter_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#             groups=num_groups,\n",
    "#             act=None,\n",
    "#             use_cudnn=use_cudnn,\n",
    "#             param_attr=ParamAttr(name=name + '_weights'),\n",
    "#             bias_attr=False)\n",
    "#         bn_name = name + '_bn'\n",
    "#         bn = fluid.layers.batch_norm(\n",
    "#             input=conv,\n",
    "#             param_attr=ParamAttr(name=bn_name + \"_scale\"),\n",
    "#             bias_attr=ParamAttr(name=bn_name + \"_offset\"),\n",
    "#             moving_mean_name=bn_name + '_mean',\n",
    "#             moving_variance_name=bn_name + '_variance')\n",
    "#         if if_act:\n",
    "#             return fluid.layers.relu6(bn)\n",
    "#         else:\n",
    "#             return bn\n",
    "\n",
    "#     def shortcut(self, input, data_residual):\n",
    "#         return fluid.layers.elementwise_add(input, data_residual)\n",
    "\n",
    "#     def inverted_residual_unit(self,\n",
    "#                               input,\n",
    "#                               num_in_filter,\n",
    "#                               num_filters,\n",
    "#                               ifshortcut,\n",
    "#                               stride,\n",
    "#                               filter_size,\n",
    "#                               padding,\n",
    "#                               expansion_factor,\n",
    "#                               name=None):\n",
    "#         num_expfilter = int(round(num_in_filter * expansion_factor))\n",
    "\n",
    "#         channel_expand = self.conv_bn_layer(\n",
    "#             input=input,\n",
    "#             num_filters=num_expfilter,\n",
    "#             filter_size=1,\n",
    "#             stride=1,\n",
    "#             padding=0,\n",
    "#             num_groups=1,\n",
    "#             if_act=True,\n",
    "#             name=name + '_expand')\n",
    "\n",
    "#         bottleneck_conv = self.conv_bn_layer(\n",
    "#             input=channel_expand,\n",
    "#             num_filters=num_expfilter,\n",
    "#             filter_size=filter_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#             num_groups=num_expfilter,\n",
    "#             if_act=True,\n",
    "#             name=name + '_dwise',\n",
    "#             use_cudnn=False)\n",
    "\n",
    "#         linear_out = self.conv_bn_layer(\n",
    "#             input=bottleneck_conv,\n",
    "#             num_filters=num_filters,\n",
    "#             filter_size=1,\n",
    "#             stride=1,\n",
    "#             padding=0,\n",
    "#             num_groups=1,\n",
    "#             if_act=False,\n",
    "#             name=name + '_linear')\n",
    "#         if ifshortcut:\n",
    "#             out = self.shortcut(input=input, data_residual=linear_out)\n",
    "#             return out\n",
    "#         else:\n",
    "#             return linear_out\n",
    "\n",
    "#     def invresi_blocks(self, input, in_c, t, c, n, s, name=None):\n",
    "#         first_block = self.inverted_residual_unit(\n",
    "#             input=input,\n",
    "#             num_in_filter=in_c,\n",
    "#             num_filters=c,\n",
    "#             ifshortcut=False,\n",
    "#             stride=s,\n",
    "#             filter_size=3,\n",
    "#             padding=1,\n",
    "#             expansion_factor=t,\n",
    "#             name=name + '_1')\n",
    "\n",
    "#         last_residual_block = first_block\n",
    "#         last_c = c\n",
    "\n",
    "#         for i in range(1, n):\n",
    "#             last_residual_block = self.inverted_residual_unit(\n",
    "#                 input=last_residual_block,\n",
    "#                 num_in_filter=last_c,\n",
    "#                 num_filters=c,\n",
    "#                 ifshortcut=True,\n",
    "#                 stride=1,\n",
    "#                 filter_size=3,\n",
    "#                 padding=1,\n",
    "#                 expansion_factor=t,\n",
    "#                 name=name + '_' + str(i + 1))\n",
    "#         return last_residual_block\n",
    "\n",
    "#     def extra_block(self, input, num_filters1, num_filters2, num_groups, stride,\n",
    "#                     scale):\n",
    "#         # 1x1 conv\n",
    "#         pointwise_conv = self.conv_bn(\n",
    "#             input=input,\n",
    "#             filter_size=1,\n",
    "#             num_filters=int(num_filters1 * scale),\n",
    "#             stride=1,\n",
    "#             num_groups=int(num_groups * scale),\n",
    "#             padding=0)\n",
    "\n",
    "#         # 3x3 conv\n",
    "#         normal_conv = self.conv_bn(\n",
    "#             input=pointwise_conv,\n",
    "#             filter_size=3,\n",
    "#             num_filters=int(num_filters2 * scale),\n",
    "#             stride=2,\n",
    "#             num_groups=int(num_groups * scale),\n",
    "#             padding=1)\n",
    "#         return normal_conv\n",
    "\n",
    "#     def conv_bn(self,\n",
    "#                 input,\n",
    "#                 filter_size,\n",
    "#                 num_filters,\n",
    "#                 stride,\n",
    "#                 padding,\n",
    "#                 channels=None,\n",
    "#                 num_groups=1,\n",
    "#                 act='relu',\n",
    "#                 use_cudnn=True):\n",
    "#         parameter_attr = ParamAttr(learning_rate=0.1, initializer=MSRA())\n",
    "#         conv = fluid.layers.conv2d(\n",
    "#             input=input,\n",
    "#             num_filters=num_filters,\n",
    "#             filter_size=filter_size,\n",
    "#             stride=stride,\n",
    "#             padding=padding,\n",
    "#             groups=num_groups,\n",
    "#             act=None,\n",
    "#             use_cudnn=use_cudnn,\n",
    "#             param_attr=parameter_attr,\n",
    "#             bias_attr=False)\n",
    "#         return fluid.layers.batch_norm(input=conv, act=act)\n",
    "\n",
    "# def MobileNetV2_x0_25(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=0.25)\n",
    "\n",
    "\n",
    "# def MobileNetV2_x0_5(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=0.5)\n",
    "\n",
    "\n",
    "# def MobileNetV2_x1_0(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=1.0)\n",
    "\n",
    "\n",
    "# def MobileNetV2_x1_5(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=1.5)\n",
    "\n",
    "\n",
    "# def MobileNetV2_x2_0(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape)\n",
    "#     return model.net(scale=2.0)\n",
    "\n",
    "\n",
    "# def MobileNetV2_scale(img, num_classes, img_shape):\n",
    "#     model = MobileNetV2SSD(img, num_classes, img_shape, change_depth=True)\n",
    "#     return model.net(scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.6 定义部分训练用到的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "import functools\n",
    "import shutil\n",
    "import math\n",
    "import multiprocessing\n",
    "\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.contrib.slim import Compressor\n",
    "\n",
    "args_learning_rate= 0.00000001\n",
    "# args_learning_rate= 0.000005\n",
    "# args_learning_rate = 0.001\n",
    "args_batch_size = 32\n",
    "args_epoc_num = 120\n",
    "args_use_gpu = True\n",
    "args_parallel = True\n",
    "args_use_multiprocess = True\n",
    "\n",
    "#保存save_persistables模型的路径\n",
    "args_model_save_dir = '/home/aistudio/work/models/quant_models'\n",
    "\n",
    "\n",
    "train_parameters = {\n",
    "    \"pascalvoc\": {\n",
    "        \"train_images\": 16551,\n",
    "        \"image_shape\": [3, 300, 300],\n",
    "        \"class_num\": 21,\n",
    "        \"batch_size\": 64,\n",
    "        \"lr\": 0.001,\n",
    "        \"lr_epochs\": [40, 60, 80, 100],\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01],\n",
    "        \"ap_version\": '11point',\n",
    "    },\n",
    "    \"coco2014\": {\n",
    "        \"train_images\": 82783,\n",
    "        \"image_shape\": [3, 300, 300],\n",
    "        \"class_num\": 81,\n",
    "        \"batch_size\": 64,\n",
    "        \"lr\": 0.001,\n",
    "        \"lr_epochs\": [12, 19],\n",
    "        \"lr_decay\": [1, 0.5, 0.25],\n",
    "        \"ap_version\": 'integral', # should use eval_coco_map.py to test model\n",
    "    },\n",
    "    \"coco2017\": {\n",
    "        \"train_images\": 118287,\n",
    "        \"image_shape\": [3, 300, 300],\n",
    "        \"class_num\": 81,\n",
    "        \"batch_size\": 64,\n",
    "        \"lr\": 0.0000001,\n",
    "        \"lr_epochs\": [12, 19],\n",
    "        \"lr_decay\": [1, 0.5, 0.25],\n",
    "        \"ap_version\": 'integral', # should use eval_coco_map.py to test model\n",
    "    }\n",
    "}\n",
    "\n",
    "train_parameters[dataset]['image_shape'] = image_shape\n",
    "train_parameters[dataset]['batch_size'] = args_batch_size\n",
    "train_parameters[dataset]['lr'] = args_learning_rate\n",
    "train_parameters[dataset]['epoc_num'] = args_epoc_num\n",
    "train_parameters[dataset]['ap_version'] = args_ap_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.7 设置优化器策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def optimizer_setting(train_params):\n",
    "#     batch_size = train_params[\"batch_size\"]\n",
    "#     iters = train_params[\"train_images\"] // batch_size\n",
    "#     lr = train_params[\"lr\"]\n",
    "#     boundaries = [i * iters  for i in train_params[\"lr_epochs\"]]\n",
    "#     values = [ i * lr for i in train_params[\"lr_decay\"]]\n",
    "\n",
    "#     optimizer = fluid.optimizer.RMSProp(\n",
    "#         learning_rate=fluid.layers.piecewise_decay(boundaries, values),\n",
    "#         # learning_rate=args_learning_rate,\n",
    "#         # learning_rate=0.1,\n",
    "#         regularization=fluid.regularizer.L2Decay(0.00005), )\n",
    "\n",
    "#     return optimizer\n",
    "\n",
    "def optimizer_setting(train_params):\n",
    "    batch_size = train_params[\"batch_size\"]\n",
    "    boundaries=[train_params[\"train_images\"] / batch_size * 10,\n",
    "                    train_params[\"train_images\"] / batch_size * 16]\n",
    "    values=[1e-4, 1e-5, 1e-6]\n",
    "    opt = fluid.optimizer.Momentum(\n",
    "        momentum=0.9,\n",
    "        learning_rate=fluid.layers.piecewise_decay(\n",
    "            boundaries=boundaries,\n",
    "            values=values),\n",
    "        regularization=fluid.regularizer.L2Decay(4e-5))\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.8 修改ssd_loss函数，替换原有框架中ssd_loss函数\n",
    "主要拆分其中nn.softmax_with_cross_entropy函数为nn.softmax和nn.cross_entropy两个函数，避免后续量化、剪枝操作后的训练中，loss为NAN的错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.layers import nn, iou_similarity, bipartite_match, target_assign, tensor, box_coder\n",
    "\n",
    "\n",
    "def ssd_loss(location,\n",
    "             confidence,\n",
    "             gt_box,\n",
    "             gt_label,\n",
    "             prior_box,\n",
    "             prior_box_var=None,\n",
    "             background_label=0,\n",
    "             overlap_threshold=0.5,\n",
    "             neg_pos_ratio=3.0,\n",
    "             neg_overlap=0.5,\n",
    "             loc_loss_weight=1.0,\n",
    "             conf_loss_weight=1.0,\n",
    "             match_type='per_prediction',\n",
    "             mining_type='max_negative',\n",
    "             normalize=True,\n",
    "             sample_size=None):\n",
    "\n",
    "    helper = LayerHelper('ssd_loss', **locals())\n",
    "    if mining_type != 'max_negative':\n",
    "        raise ValueError(\"Only support mining_type == max_negative now.\")\n",
    "\n",
    "    num, num_prior, num_class = confidence.shape\n",
    "    conf_shape = nn.shape(confidence)\n",
    "\n",
    "    def __reshape_to_2d(var):\n",
    "        return nn.flatten(x=var, axis=2)\n",
    "\n",
    "    # 1. Find matched boundding box by prior box.\n",
    "    #   1.1 Compute IOU similarity between ground-truth boxes and prior boxes.\n",
    "    iou = iou_similarity(x=gt_box, y=prior_box)\n",
    "    #   1.2 Compute matched boundding box by bipartite matching algorithm.\n",
    "    matched_indices, matched_dist = bipartite_match(iou, match_type,\n",
    "                                                    overlap_threshold)\n",
    "\n",
    "    # 2. Compute confidence for mining hard examples\n",
    "    # 2.1. Get the target label based on matched indices\n",
    "    gt_label = nn.reshape(\n",
    "        x=gt_label, shape=(len(gt_label.shape) - 1) * (0, ) + (-1, 1))\n",
    "    gt_label.stop_gradient = True\n",
    "    target_label, _ = target_assign(\n",
    "        gt_label, matched_indices, mismatch_value=background_label)\n",
    "    # 2.2. Compute confidence loss.\n",
    "    # Reshape confidence to 2D tensor.\n",
    "    confidence = __reshape_to_2d(confidence)\n",
    "    target_label = tensor.cast(x=target_label, dtype='int64')\n",
    "    target_label = __reshape_to_2d(target_label)\n",
    "    target_label.stop_gradient = True\n",
    "    #conf_loss = nn.softmax_with_cross_entropy(confidence, target_label)\n",
    "    conf_softmax = nn.softmax(confidence,use_cudnn=False)\n",
    "    conf_loss = nn.cross_entropy(conf_softmax, target_label)\n",
    "    # 3. Mining hard examples\n",
    "    actual_shape = nn.slice(conf_shape, axes=[0], starts=[0], ends=[2])\n",
    "    actual_shape.stop_gradient = True\n",
    "    conf_loss = nn.reshape(\n",
    "        x=conf_loss, shape=(num, num_prior), actual_shape=actual_shape)\n",
    "    conf_loss.stop_gradient = True\n",
    "    neg_indices = helper.create_variable_for_type_inference(dtype='int32')\n",
    "    dtype = matched_indices.dtype\n",
    "    updated_matched_indices = helper.create_variable_for_type_inference(\n",
    "        dtype=dtype)\n",
    "    helper.append_op(\n",
    "        type='mine_hard_examples',\n",
    "        inputs={\n",
    "            'ClsLoss': conf_loss,\n",
    "            'LocLoss': None,\n",
    "            'MatchIndices': matched_indices,\n",
    "            'MatchDist': matched_dist,\n",
    "        },\n",
    "        outputs={\n",
    "            'NegIndices': neg_indices,\n",
    "            'UpdatedMatchIndices': updated_matched_indices\n",
    "        },\n",
    "        attrs={\n",
    "            'neg_pos_ratio': neg_pos_ratio,\n",
    "            'neg_dist_threshold': neg_overlap,\n",
    "            'mining_type': mining_type,\n",
    "            'sample_size': sample_size,\n",
    "        })\n",
    "\n",
    "    # 4. Assign classification and regression targets\n",
    "    # 4.1. Encoded bbox according to the prior boxes.\n",
    "    encoded_bbox = box_coder(\n",
    "        prior_box=prior_box,\n",
    "        prior_box_var=prior_box_var,\n",
    "        target_box=gt_box,\n",
    "        code_type='encode_center_size')\n",
    "    # 4.2. Assign regression targets\n",
    "    target_bbox, target_loc_weight = target_assign(\n",
    "        encoded_bbox, updated_matched_indices, mismatch_value=background_label)\n",
    "    # 4.3. Assign classification targets\n",
    "    target_label, target_conf_weight = target_assign(\n",
    "        gt_label,\n",
    "        updated_matched_indices,\n",
    "        negative_indices=neg_indices,\n",
    "        mismatch_value=background_label)\n",
    "\n",
    "    # 5. Compute loss.\n",
    "    # 5.1 Compute confidence loss.\n",
    "    target_label = __reshape_to_2d(target_label)\n",
    "    target_label = tensor.cast(x=target_label, dtype='int64')\n",
    "\n",
    "    # conf_loss = nn.softmax_with_cross_entropy(confidence, target_label)\n",
    "    conf_softmax = nn.softmax(confidence, use_cudnn=False)\n",
    "    conf_loss = nn.cross_entropy(conf_softmax, target_label)\n",
    "    target_conf_weight = __reshape_to_2d(target_conf_weight)\n",
    "    conf_loss = conf_loss * target_conf_weight\n",
    "\n",
    "    # the target_label and target_conf_weight do not have gradient.\n",
    "    target_label.stop_gradient = True\n",
    "    target_conf_weight.stop_gradient = True\n",
    "\n",
    "    # 5.2 Compute regression loss.\n",
    "    location = __reshape_to_2d(location)\n",
    "    target_bbox = __reshape_to_2d(target_bbox)\n",
    "\n",
    "    loc_loss = nn.smooth_l1(location, target_bbox)\n",
    "    target_loc_weight = __reshape_to_2d(target_loc_weight)\n",
    "    loc_loss = loc_loss * target_loc_weight\n",
    "\n",
    "    # the target_bbox and target_loc_weight do not have gradient.\n",
    "    target_bbox.stop_gradient = True\n",
    "    target_loc_weight.stop_gradient = True\n",
    "\n",
    "    # 5.3 Compute overall weighted loss.\n",
    "    loss = conf_loss_weight * conf_loss + loc_loss_weight * loc_loss\n",
    "    # reshape to [N, Np], N is the batch size and Np is the prior box number.\n",
    "    loss = nn.reshape(x=loss, shape=(num, num_prior), actual_shape=actual_shape)\n",
    "    loss = nn.reduce_sum(loss, dim=1, keep_dim=True)\n",
    "    if normalize:\n",
    "        normalizer = nn.reduce_sum(target_loc_weight)\n",
    "        loss = loss / normalizer\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.9 定义执行程序用到的`program`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_program(main_prog, startup_prog, train_params, is_train):\n",
    "    image_shape = train_params['image_shape']\n",
    "    class_num = train_params['class_num']\n",
    "    ap_version = train_params['ap_version']\n",
    "    outs = []\n",
    "    with fluid.program_guard(main_prog, startup_prog):\n",
    "        py_reader = fluid.layers.py_reader(\n",
    "            capacity=64,\n",
    "            shapes=[[-1] + image_shape, [-1, 4], [-1, 1], [-1, 1]],\n",
    "            lod_levels=[0, 1, 1, 1],\n",
    "            dtypes=[\"float32\", \"float32\", \"int32\", \"int32\"],\n",
    "            use_double_buffer=True)\n",
    "        with fluid.unique_name.guard():\n",
    "            image, gt_box, gt_label, difficult = fluid.layers.read_file(py_reader)\n",
    "            locs, confs, box, box_var = mobile_net(class_num, image, image_shape)\n",
    "            # locs, confs, box, box_var = MobileNetV2_x1_0(image, class_num, image_shape)\n",
    "            boxes = fluid.layers.box_coder(\n",
    "                prior_box=box,\n",
    "                prior_box_var=box_var,\n",
    "                target_box=locs,\n",
    "                code_type='decode_center_size')\n",
    "            scores = fluid.layers.nn.softmax(input=confs)\n",
    "            scores = fluid.layers.nn.transpose(scores, perm=[0, 2, 1])\n",
    "            scores.stop_gradient = True\n",
    "            \n",
    "            inference_fetch_list = [boxes] + [scores]\n",
    "            # print(\"inference_fetch_list: {}\".format(inference_fetch_list))\n",
    "            gt_label.stop_gradient=True\n",
    "            difficult.stop_gradient=True\n",
    "            gt_box.stop_gradient=True\n",
    "            if is_train:\n",
    "                with fluid.unique_name.guard(\"train\"):\n",
    "                    loss = ssd_loss(locs, confs, gt_box, gt_label, box,\n",
    "                        box_var)\n",
    "                    loss = fluid.layers.reduce_sum(loss)\n",
    "                    optimizer = optimizer_setting(train_params)\n",
    "                    optimizer.minimize(loss)\n",
    "                    # print(\"loss: {}\".format(loss))\n",
    "                outs = [py_reader,(image, gt_box, gt_label, difficult), loss, optimizer, inference_fetch_list]\n",
    "            else:\n",
    "                with fluid.unique_name.guard(\"inference\"):\n",
    "                    # nmsed_out = fluid.layers.detection_output(\n",
    "                    #     locs, confs, box, box_var, nms_top_k=-1, nms_threshold=0.45, keep_top_k=-1)#输出一个LoDTensor，形为[No,6]。每行有6个值：[label,confidence,xmin,ymin,xmax,ymax]\n",
    "                    # confs = fluid.layers.transpose(confs, perm=[0, 2, 1])\n",
    "                    decoded_box = fluid.layers.box_coder(\n",
    "                        prior_box=box,\n",
    "                        prior_box_var=box_var,\n",
    "                        target_box=locs,\n",
    "                        code_type='decode_center_size')\n",
    "                    confs = fluid.layers.softmax(input=confs)\n",
    "                    confs = fluid.layers.transpose(confs, perm=[0, 2, 1])\n",
    "                    confs.stop_gradient = True\n",
    "                    nmsed_out = fluid.layers.multiclass_nms(\n",
    "                        bboxes=decoded_box,\n",
    "                        scores=confs,\n",
    "                        score_threshold=0.01,\n",
    "                        nms_top_k=-1,\n",
    "                        nms_threshold=0.45,\n",
    "                        keep_top_k=-1,\n",
    "                        normalized=False)\n",
    "                    # print(\"nmsed_out: {}\".format(nmsed_out))\n",
    "                    gt_label = fluid.layers.cast(x=gt_label, dtype=gt_box.dtype)\n",
    "                    if difficult:\n",
    "                        difficult = fluid.layers.cast(x=difficult, dtype=gt_box.dtype)\n",
    "                        gt_label = fluid.layers.reshape(gt_label, [-1, 1])\n",
    "                        difficult = fluid.layers.reshape(difficult, [-1, 1])\n",
    "                        label = fluid.layers.concat([gt_label, difficult, gt_box], axis=1)\n",
    "                    else:\n",
    "                        label = fluid.layers.concat([gt_label, gt_box], axis=1)\n",
    "                    map_eval = fluid.layers.detection.detection_map(\n",
    "                        nmsed_out,\n",
    "                        label,\n",
    "                        class_num,\n",
    "                        background_label=0,\n",
    "                        overlap_threshold=0.5,\n",
    "                        evaluate_difficult=False,\n",
    "                        ap_version=ap_version)\n",
    "                    # print(\"map_eval: {}\".format(map_eval))\n",
    "                # nmsed_out and image is used to save mode for inference\n",
    "                outs = [py_reader, (image, gt_box, gt_label, difficult), map_eval, nmsed_out, image]\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.10 定义部分变量参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_save_dir = args_model_save_dir\n",
    "pretrained_model = args_pretrained_model\n",
    "use_gpu = args_use_gpu\n",
    "parallel = args_parallel\n",
    "is_shuffle = True\n",
    "use_multiprocess = args_use_multiprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.11 定义训练、测试的`program`、`reader`等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not use_gpu:\n",
    "    devices_num = int(os.environ.get('CPU_NUM',\n",
    "                          multiprocessing.cpu_count()))\n",
    "    # devices_num = 1\n",
    "else:\n",
    "    devices_num = fluid.core.get_cuda_device_count()\n",
    "\n",
    "batch_size = train_parameters[dataset]['batch_size']\n",
    "epoc_num = train_parameters[dataset]['epoc_num']\n",
    "\n",
    "batch_size_per_device = batch_size // devices_num \n",
    "\n",
    "startup_prog = fluid.Program()\n",
    "train_prog = fluid.Program()\n",
    "test_prog = fluid.Program()\n",
    "\n",
    "train_py_reader, train_inputs, loss, optimizer, inference_fetch_list = build_program(\n",
    "        main_prog=train_prog,\n",
    "        startup_prog=startup_prog,\n",
    "        train_params=train_parameters[dataset],\n",
    "        is_train=True)\n",
    "test_py_reader, test_inputs, map_var, nmsed_out, image = build_program(\n",
    "        main_prog=test_prog,\n",
    "        startup_prog=startup_prog,\n",
    "        train_params=train_parameters[dataset],\n",
    "        is_train=False)\n",
    "\n",
    "# train_inputs, loss, optimizer = build_program(\n",
    "#         main_prog=train_prog,\n",
    "#         startup_prog=startup_prog,\n",
    "#         train_params=train_parameters[dataset],\n",
    "#         is_train=True)\n",
    "    \n",
    "# test_inputs, map_var, _, _ = build_program(\n",
    "#         main_prog=test_prog,\n",
    "#         startup_prog=startup_prog,\n",
    "#         train_params=train_parameters[dataset],\n",
    "#         is_train=False)\n",
    "    \n",
    "test_prog = test_prog.clone(for_test=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.12 定义训练环境相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "exe.run(startup_prog)\n",
    "    \n",
    "if pretrained_model:\n",
    "    def if_exist(var):\n",
    "        return os.path.exists(os.path.join(pretrained_model, var.name))\n",
    "    fluid.io.load_vars(exe, pretrained_model, main_program=train_prog,\n",
    "                           predicate=if_exist)\n",
    "\n",
    "# for param in train_prog.global_block().all_parameters():\n",
    "    # print(\"param name: {}\".format(param.name))\n",
    "    # print(\"name: {}; shape: {}\".format(param.name, param.shape))\n",
    "\n",
    "# if parallel:\n",
    "#     loss.persistable = True\n",
    "#     build_strategy = fluid.BuildStrategy()\n",
    "#     build_strategy.enable_inplace = True\n",
    "#     build_strategy.memory_optimize = True\n",
    "#     train_exe = fluid.ParallelExecutor(main_program=train_prog,\n",
    "#         use_cuda=use_gpu, loss_name=loss.name, build_strategy=build_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.13 获取训练、测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pycocotools \n",
    "num_workers = 8\n",
    "train_reader = train_data_reader(data_args,\n",
    "                                train_file_list,\n",
    "                                batch_size_per_device,\n",
    "                                shuffle=is_shuffle,\n",
    "                                use_multiprocess=use_multiprocess,\n",
    "                                num_workers=num_workers)\n",
    "train_py_reader.decorate_paddle_reader(train_reader)\n",
    "\n",
    "test_reader = test_data_reader(data_args, val_file_list, batch_size)\n",
    "test_py_reader.decorate_paddle_reader(test_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.14 定义训练、测试的输入、输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image, gt_box, gt_label, difficult = train_inputs\n",
    "# train_feed_list = [(\"image\", \"image\"), (\"gt_box\", \"gt_box\"), (\"gt_label\", \"gt_label\"), (\"difficult\", \"difficult\")]\n",
    "train_feed_list = [(\"image\", image.name), (\"gt_box\", gt_box.name), (\"gt_label\", gt_label.name), (\"difficult\", difficult.name)]\n",
    "train_fetch_list=[(\"loss\", loss.name)]\n",
    "\n",
    "image, gt_box, gt_label, difficult = test_inputs\n",
    "# val_feed_list=[(\"image\", \"image\"), (\"gt_box\", \"gt_box\"), (\"gt_label\", \"gt_label\"), (\"difficult\", \"difficult\")]\n",
    "val_feed_list = [(\"image\", image.name), (\"gt_box\", gt_box.name), (\"gt_label\", gt_label.name), (\"difficult\", difficult.name)]\n",
    "val_fetch_list=[(\"map\",  map_var.name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.15 定义剪枝、量化配置策略的配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "#先裁剪，再量化配置\n",
    "config=\"\"\"\n",
    "version: 1.0\n",
    "pruners:\n",
    "    pruner_1:\n",
    "        class: 'StructurePruner'\n",
    "        pruning_axis:\n",
    "            '*': 0\n",
    "        criterions:\n",
    "            '*': 'l1_norm'\n",
    "strategies:\n",
    "    uniform_pruning_strategy:\n",
    "        class: 'UniformPruneStrategy'\n",
    "        pruner: 'pruner_1'\n",
    "        start_epoch: 0\n",
    "        target_ratio: 0.05\n",
    "        # pruned_params: 'conv2d_2.w_0|conv2d_4.w_0|conv2d_[6-9].w_0|conv2d_1[0-1].w_0'\n",
    "        pruned_params: 'conv2d_[5-6].w_0'\n",
    "        metric_name: 'map'\n",
    "    quantization_strategy:\n",
    "        class: 'QuantizationStrategy'\n",
    "        # start_epoch: 121\n",
    "        # end_epoch: 141\n",
    "        start_epoch: 1\n",
    "        end_epoch: 2\n",
    "        float_model_save_path: '/home/aistudio/work/models/output/float'\n",
    "        mobile_model_save_path: '/home/aistudio/work/models/output/mobile'\n",
    "        int8_model_save_path: '/home/aistudio/work/models/output/int8'\n",
    "        weight_bits: 8\n",
    "        activation_bits: 8\n",
    "        weight_quantize_type: 'abs_max'\n",
    "        activation_quantize_type: 'abs_max'\n",
    "        # save_in_nodes: ['image']\n",
    "        # save_out_nodes: ['inferenceinferencedetection_output_0.tmp_0']\n",
    "compressor:\n",
    "    # epoch: 142\n",
    "    epoch: 3\n",
    "    # Please enable this option for loading checkpoint.\n",
    "    # init_model: '/home/aistudio/work/models/checkpoints_1/7/'\n",
    "    checkpoint_path: '/home/aistudio/work/models/checkpoints/'\n",
    "    strategies:\n",
    "        - uniform_pruning_strategy\n",
    "        - quantization_strategy\n",
    "\"\"\"\n",
    "\n",
    "f = open(\"/home/aistudio/work/models/compress.yaml\", 'w')\n",
    "f.write(config)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # -*- coding: UTF-8 -*-\n",
    "# #先裁剪，再量化配置\n",
    "# config=\"\"\"\n",
    "# version: 1.0\n",
    "# pruners:\n",
    "#     pruner_1:\n",
    "#         class: 'StructurePruner'\n",
    "#         pruning_axis:\n",
    "#             '*': 0\n",
    "#         criterions:\n",
    "#             '*': 'l1_norm'\n",
    "# strategies:\n",
    "#     uniform_pruning_strategy:\n",
    "#         class: 'UniformPruneStrategy'\n",
    "#         pruner: 'pruner_1'\n",
    "#         start_epoch: 0\n",
    "#         target_ratio: 0.50\n",
    "#         pruned_params: '.*_sep_weights'\n",
    "#         metric_name: 'map'\n",
    "#     quantization_strategy:\n",
    "#         class: 'QuantizationStrategy'\n",
    "#         # start_epoch: 121\n",
    "#         # end_epoch: 141\n",
    "#         start_epoch: 12\n",
    "#         end_epoch: 13\n",
    "#         float_model_save_path: '/home/aistudio/work/models/output/float'\n",
    "#         mobile_model_save_path: '/home/aistudio/work/models/output/mobile'\n",
    "#         int8_model_save_path: '/home/aistudio/work/models/output/int8'\n",
    "#         weight_bits: 8\n",
    "#         activation_bits: 8\n",
    "#         weight_quantize_type: 'abs_max'\n",
    "#         activation_quantize_type: 'abs_max'\n",
    "#         # save_in_nodes: ['image']\n",
    "#         # save_out_nodes: ['inferenceinferencedetection_output_0.tmp_0']\n",
    "# compressor:\n",
    "#     # epoch: 142\n",
    "#     epoch: 14\n",
    "#     # Please enable this option for loading checkpoint.\n",
    "#     # init_model: '/home/aistudio/work/models/checkpoints/4/'\n",
    "#     checkpoint_path: '/home/aistudio/work/models/checkpoints/'\n",
    "#     strategies:\n",
    "#         - uniform_pruning_strategy\n",
    "#         - quantization_strategy\n",
    "# \"\"\"\n",
    "\n",
    "# f = open(\"/home/aistudio/work/models/compress.yaml\", 'w')\n",
    "# f.write(config)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # -*- coding: UTF-8 -*-\n",
    "# #量化配置\n",
    "# config=\"\"\"\n",
    "# version: 1.0\n",
    "# strategies:\n",
    "#     quantization_strategy:\n",
    "#         class: 'QuantizationStrategy'\n",
    "#         start_epoch: 0\n",
    "#         end_epoch: 1\n",
    "#         float_model_save_path: '/home/aistudio/work/models/output/float'\n",
    "#         mobile_model_save_path: '/home/aistudio/work/models/output/mobile'\n",
    "#         int8_model_save_path: '/home/aistudio/work/models/output/int8'\n",
    "#         weight_bits: 8\n",
    "#         activation_bits: 8\n",
    "#         weight_quantize_type: 'abs_max'\n",
    "#         activation_quantize_type: 'abs_max'\n",
    "#         # save_in_nodes: ['image']\n",
    "#         # save_out_nodes: ['inferenceinferencedetection_output_0.tmp_0']\n",
    "# compressor:\n",
    "#     epoch: 2\n",
    "#     checkpoint_path: '/home/aistudio/work/models/checkpoints/'\n",
    "#     strategies:\n",
    "#         - quantization_strategy\n",
    "# \"\"\"\n",
    "\n",
    "# f = open(\"/home/aistudio/work/models/compress.yaml\", 'w')\n",
    "# f.write(config)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # -*- coding: UTF-8 -*-\n",
    "# #剪裁配置\n",
    "# config=\"\"\"\n",
    "# version: 1.0\n",
    "# pruners:\n",
    "#     pruner_1:\n",
    "#         class: 'StructurePruner'\n",
    "#         pruning_axis:\n",
    "#             '*': 0\n",
    "#         criterions:\n",
    "#             '*': 'l1_norm'\n",
    "# strategies:\n",
    "#     uniform_pruning_strategy:\n",
    "#         class: 'UniformPruneStrategy'\n",
    "#         pruner: 'pruner_1'\n",
    "#         start_epoch: 0\n",
    "#         target_ratio: 0.5\n",
    "#         pruned_params: '.*_sep_weights'\n",
    "#         metric_name: 'map'\n",
    "# compressor:\n",
    "#     epoch: 2\n",
    "#     #init_model: './checkpoints/0' # Please enable this option for loading checkpoint.\n",
    "#     checkpoint_path: '/home/aistudio/work/models/checkpoints/'\n",
    "#     strategies:\n",
    "#         - uniform_pruning_strategy\n",
    "# \"\"\"\n",
    "\n",
    "# f = open(\"/home/aistudio/work/models/compress.yaml\", 'w')\n",
    "# f.write(config)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.16 执行剪枝、量化训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "com_pass = Compressor(\n",
    "        place,\n",
    "        fluid.global_scope(),\n",
    "        train_prog,\n",
    "        train_reader=train_py_reader,\n",
    "        # train_feed_list=train_feed_list,\n",
    "        train_feed_list=None,\n",
    "        train_fetch_list=train_fetch_list,\n",
    "        eval_program=test_prog,\n",
    "        eval_reader=test_py_reader,\n",
    "        # eval_feed_list=val_feed_list,\n",
    "        eval_feed_list=None,\n",
    "        eval_fetch_list=val_fetch_list,\n",
    "        train_optimizer=None)\n",
    "com_pass.config('/home/aistudio/work/models/compress.yaml')\n",
    "eval_graph = com_pass.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.17 保存剪枝、量化后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peuned_program = com_pass.eval_graph.program\n",
    "# for param in peuned_program.global_block().all_parameters():\n",
    "#     print(\"param name: {}\".format(param.name))\n",
    "fluid.io.save_inference_model(\"/home/aistudio/work/models/pruned_models/20190915_best_1\", feeded_var_names=[image.name], target_vars=inference_fetch_list, executor=exe, main_program=peuned_program)\n",
    "fluid.io.save_persistables(exe, model_save_dir + \"/20190915_best_1\", main_program=peuned_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.18 计算分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#计算分数\n",
    "!/bin/bash /home/aistudio/work/astar2019/testssd.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.1.19 提交模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#提交模型\n",
    "# !zip -r /home/aistudio/work/models_20190804/submit/submit_model.zip /home/aistudio/work/models/pruned_models/20190915_best\n",
    "# !cd /home/aistudio/work/models_20190804/submit && rm -rf submit.sh && wget -O submit.sh http://ai-studio-static.bj.bcebos.com/script/submit.sh && sh submit.sh /home/aistudio/work/models_20190804/submit/submit_model.zip bb76abd7312b4bf28aa5770c0a57053f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.5.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
